# Model Provider Configuration for AgentX
#
# This file defines available models and their capabilities.
# Provider API keys should be set via environment variables or .env file.

providers:
  lmstudio:
    base_url_env: LMSTUDIO_BASE_URL
    timeout: 300.0  # Local models may be slower
    max_retries: 1

  anthropic:
    api_key_env: ANTHROPIC_API_KEY
    timeout: 60.0
    max_retries: 3

  openai:
    api_key_env: OPENAI_API_KEY
    # base_url: https://api.openai.com/v1  # Optional, for proxies
    timeout: 60.0
    max_retries: 3

models:
  # OpenAI Models
  gpt-4-turbo:
    provider: openai
    context_window: 128000
    supports_tools: true
    supports_vision: true
    supports_streaming: true
    cost_per_1k_input: 0.01
    cost_per_1k_output: 0.03

  gpt-4o:
    provider: openai
    context_window: 128000
    supports_tools: true
    supports_vision: true
    supports_streaming: true
    cost_per_1k_input: 0.005
    cost_per_1k_output: 0.015

  gpt-4o-mini:
    provider: openai
    context_window: 128000
    supports_tools: true
    supports_vision: true
    supports_streaming: true
    cost_per_1k_input: 0.00015
    cost_per_1k_output: 0.0006

  gpt-3.5-turbo:
    provider: openai
    context_window: 16385
    supports_tools: true
    supports_vision: false
    supports_streaming: true
    cost_per_1k_input: 0.0005
    cost_per_1k_output: 0.0015

  # Anthropic Models
  claude-3-opus:
    provider: anthropic
    model_id: claude-3-opus-20240229
    context_window: 200000
    supports_tools: true
    supports_vision: true
    supports_streaming: true
    cost_per_1k_input: 0.015
    cost_per_1k_output: 0.075

  claude-3-sonnet:
    provider: anthropic
    model_id: claude-3-sonnet-20240229
    context_window: 200000
    supports_tools: true
    supports_vision: true
    supports_streaming: true
    cost_per_1k_input: 0.003
    cost_per_1k_output: 0.015

  claude-3-haiku:
    provider: anthropic
    model_id: claude-3-haiku-20240307
    context_window: 200000
    supports_tools: true
    supports_vision: true
    supports_streaming: true
    cost_per_1k_input: 0.00025
    cost_per_1k_output: 0.00125

  claude-3.5-sonnet:
    provider: anthropic
    model_id: claude-3-5-sonnet-20241022
    context_window: 200000
    supports_tools: true
    supports_vision: true
    supports_streaming: true
    cost_per_1k_input: 0.003
    cost_per_1k_output: 0.015

  claude-3.5-haiku:
    provider: anthropic
    model_id: claude-3-5-haiku-20241022
    context_window: 200000
    supports_tools: true
    supports_vision: true
    supports_streaming: true
    cost_per_1k_input: 0.001
    cost_per_1k_output: 0.005

  # LM Studio (Local) Models
  # These models are served locally via LM Studio's OpenAI-compatible API
  llama3.2:
    provider: lmstudio
    context_window: 128000
    supports_tools: true
    supports_vision: false
    supports_streaming: true
    local: true
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0

  llama3.1:
    provider: lmstudio
    context_window: 128000
    supports_tools: true
    supports_vision: false
    supports_streaming: true
    local: true
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0

  mistral:
    provider: lmstudio
    context_window: 32768
    supports_tools: true
    supports_vision: false
    supports_streaming: true
    local: true
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0

  mixtral:
    provider: lmstudio
    context_window: 32768
    supports_tools: true
    supports_vision: false
    supports_streaming: true
    local: true
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0

  codellama:
    provider: lmstudio
    context_window: 16384
    supports_tools: false
    supports_vision: false
    supports_streaming: true
    local: true
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0

  qwen2.5:
    provider: lmstudio
    context_window: 128000
    supports_tools: true
    supports_vision: false
    supports_streaming: true
    local: true
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0

  deepseek-coder-v2:
    provider: lmstudio
    context_window: 128000
    supports_tools: false
    supports_vision: false
    supports_streaming: true
    local: true
    cost_per_1k_input: 0.0
    cost_per_1k_output: 0.0

# Default models for different use cases
defaults:
  chat: gpt-4o-mini
  reasoning: claude-3.5-sonnet
  code: deepseek-coder-v2
  fast: gpt-3.5-turbo
  local: llama3.2
