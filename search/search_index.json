{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AgentX Documentation","text":"<p>Welcome to the AgentX documentation. AgentX is a hybrid desktop application combining AI-powered language translation with a sophisticated memory system.</p>"},{"location":"#overview","title":"Overview","text":"<p>AgentX is built on a modern, two-tier architecture:</p> <ul> <li>Backend: Django REST API providing AI-powered services</li> <li>Frontend: Tauri desktop application with React/TypeScript</li> <li>AI Features: Multi-level translation using HuggingFace transformers (NLLB-200, M2M100)</li> <li>Memory Stack: Neo4j graph database, PostgreSQL with pgvector, and Redis</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#translation-system","title":"Translation System","text":"<p>Multi-level language detection and translation supporting 200+ languages:</p> <ul> <li>Fast initial detection (~20 languages)</li> <li>Comprehensive translation using NLLB-200 architecture</li> <li>Confidence scoring and fallback mechanisms</li> </ul>"},{"location":"#memory-system","title":"Memory System","text":"<p>Hybrid memory architecture combining:</p> <ul> <li>Neo4j: Graph-based relationship analysis</li> <li>PostgreSQL + pgvector: Vector embeddings for semantic search</li> <li>Redis: Fast in-memory caching</li> </ul>"},{"location":"#desktop-application","title":"Desktop Application","text":"<p>Native desktop experience with:</p> <ul> <li>Tab-based interface (Dashboard, Translation, Chat, Tools)</li> <li>Cross-platform support via Tauri v2</li> <li>Fast development with Vite + React 19</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li> <p>:material-rocket-launch:{ .lg .middle } Getting Started</p> <p>Install and run AgentX in minutes</p> <p>:octicons-arrow-right-24: Installation</p> </li> <li> <p>:material-code-braces:{ .lg .middle } Development</p> <p>Set up your development environment</p> <p>:octicons-arrow-right-24: Setup Guide</p> </li> <li> <p>:material-api:{ .lg .middle } API Reference</p> <p>Explore the REST API endpoints</p> <p>:octicons-arrow-right-24: API Docs</p> </li> <li> <p>:material-database:{ .lg .middle } Database Stack</p> <p>Learn about the database architecture</p> <p>:octicons-arrow-right-24: Databases</p> </li> </ul>"},{"location":"#architecture-at-a-glance","title":"Architecture at a Glance","text":"<pre><code>graph TB\n    Client[Tauri Client&lt;br/&gt;React + TypeScript]\n    API[Django API&lt;br/&gt;Port 12319]\n    Neo4j[Neo4j&lt;br/&gt;Graph DB]\n    Postgres[PostgreSQL&lt;br/&gt;+ pgvector]\n    Redis[Redis&lt;br/&gt;Cache]\n\n    Client --&gt;|HTTP| API\n    API --&gt; Neo4j\n    API --&gt; Postgres\n    API --&gt; Redis</code></pre>"},{"location":"#technology-stack","title":"Technology Stack","text":"Layer Technology Purpose Frontend Tauri v2 + React 19 Desktop application shell Build Vite + TypeScript Fast development &amp; bundling Backend Django 5.2.8 REST API framework AI/ML HuggingFace Transformers Language models Graph DB Neo4j 5.15 Relationship analysis Vector DB PostgreSQL + pgvector Semantic search Cache Redis 7 In-memory data store Task Runner Task (Taskfile) Development automation Package Manager uv Fast Python dependency management"},{"location":"#project-status","title":"Project Status","text":"<p>AgentX is under active development. Key features:</p> <ul> <li> Django API with translation endpoints</li> <li> Tauri desktop application</li> <li> Two-level translation system</li> <li> Database stack (Neo4j, Postgres, Redis)</li> <li> Memory graph implementation</li> <li> Vector embedding system</li> <li> Chat interface</li> <li> Production deployment</li> </ul>"},{"location":"#license","title":"License","text":"<p>[Add your license information here]</p>"},{"location":"api/endpoints/","title":"API Endpoints","text":"<p>REST API endpoint reference.</p>"},{"location":"api/endpoints/#base-url","title":"Base URL","text":"<pre><code>http://localhost:12319/api/\n</code></pre>"},{"location":"api/endpoints/#endpoints","title":"Endpoints","text":""},{"location":"api/endpoints/#health-check","title":"Health Check","text":"<pre><code>GET /api/index\n</code></pre> <p>Returns API status.</p>"},{"location":"api/endpoints/#language-detection","title":"Language Detection","text":"<pre><code>GET /api/language-detect\n</code></pre> <p>Detects language from test text.</p>"},{"location":"api/endpoints/#translation","title":"Translation","text":"<pre><code>POST /api/translate\nContent-Type: application/json\n\n{\n  \"text\": \"Hello, world!\",\n  \"target_language\": \"fr\"\n}\n</code></pre> <p>Translates text to target language using ISO 639-1 codes.</p> <p>Response: <pre><code>{\n  \"original\": \"Hello, world!\",\n  \"translated\": \"Bonjour le monde!\",\n  \"source_language\": \"en\",\n  \"target_language\": \"fr\"\n}\n</code></pre></p>"},{"location":"api/endpoints/#authentication","title":"Authentication","text":"<p>Currently no authentication required (development mode).</p>"},{"location":"api/models/","title":"API Models","text":"<p>Data models and schemas used by the API.</p>"},{"location":"api/models/#translation-request","title":"Translation Request","text":"<pre><code>{\n  \"text\": \"string (required)\",\n  \"target_language\": \"string (required, ISO 639-1)\",\n  \"source_language\": \"string (optional, auto-detect)\"\n}\n</code></pre>"},{"location":"api/models/#translation-response","title":"Translation Response","text":"<pre><code>{\n  \"original\": \"string\",\n  \"translated\": \"string\",\n  \"source_language\": \"string\",\n  \"target_language\": \"string\",\n  \"confidence\": \"float (optional)\"\n}\n</code></pre>"},{"location":"api/models/#language-detection","title":"Language Detection","text":"<pre><code>{\n  \"text\": \"string\",\n  \"detected_language\": \"string (ISO 639-1)\",\n  \"confidence\": \"float\"\n}\n</code></pre>"},{"location":"architecture/api/","title":"API Layer","text":"<p>The Django REST API provides AI-powered services for translation and memory management.</p>"},{"location":"architecture/api/#overview","title":"Overview","text":"<ul> <li>Framework: Django 5.2.8</li> <li>Port: 12319</li> <li>Base URL: <code>http://localhost:12319/api/</code></li> </ul>"},{"location":"architecture/api/#key-components","title":"Key Components","text":""},{"location":"architecture/api/#translation-kit-apiagentx_aikittranslationpy","title":"Translation Kit (<code>api/agentx_ai/kit/translation.py</code>)","text":"<p>Handles language detection and translation using HuggingFace models.</p>"},{"location":"architecture/api/#conversation-system-apiagentx_aikitconversationpy","title":"Conversation System (<code>api/agentx_ai/kit/conversation.py</code>)","text":"<p>Manages conversation state and context (planned).</p>"},{"location":"architecture/api/#memory-graph-apiagentx_aikitlibmemory_graphpy","title":"Memory Graph (<code>api/agentx_ai/kit/lib/memory_graph.py</code>)","text":"<p>Graph-based memory system using Neo4j (in development).</p>"},{"location":"architecture/api/#api-endpoints","title":"API Endpoints","text":"<p>See API Reference for complete endpoint documentation.</p>"},{"location":"architecture/api/#next-steps","title":"Next Steps","text":"<ul> <li>API Endpoints - Complete API reference</li> <li>Database Integration - How API connects to databases</li> </ul>"},{"location":"architecture/client/","title":"Client Layer","text":"<p>The Tauri desktop application provides the user interface for AgentX.</p>"},{"location":"architecture/client/#technology-stack","title":"Technology Stack","text":"<ul> <li>Desktop Framework: Tauri v2</li> <li>Frontend: React 19 with TypeScript</li> <li>Build Tool: Vite</li> <li>Styling: CSS Modules (or your choice)</li> </ul>"},{"location":"architecture/client/#project-structure","title":"Project Structure","text":"<pre><code>client/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 App.tsx              # Main app component\n\u2502   \u251c\u2500\u2500 components/          # React components\n\u2502   \u2502   \u251c\u2500\u2500 TabBar.tsx       # Tab navigation\n\u2502   \u2502   \u2514\u2500\u2500 tabs/            # Tab components\n\u2502   \u2514\u2500\u2500 main.tsx             # Entry point\n\u251c\u2500\u2500 src-tauri/               # Rust/Tauri backend\n\u2502   \u251c\u2500\u2500 Cargo.toml\n\u2502   \u251c\u2500\u2500 tauri.conf.json\n\u2502   \u2514\u2500\u2500 src/\n\u2514\u2500\u2500 vite.config.ts\n</code></pre>"},{"location":"architecture/client/#tab-system","title":"Tab System","text":"<p>Four main tabs with persistent state:</p> <ol> <li>Dashboard - Overview and stats</li> <li>Translation - Interactive translation</li> <li>Chat - AI conversations</li> <li>Tools - Utilities and settings</li> </ol> <p>All tabs remain mounted; visibility controlled via CSS.</p>"},{"location":"architecture/client/#development","title":"Development","text":"<ul> <li>Dev server: <code>http://localhost:1420</code> (Vite)</li> <li>HMR enabled for fast iteration</li> <li>Tauri window wraps the Vite dev server</li> </ul> <p>See Development Setup for more information.</p>"},{"location":"architecture/databases/","title":"Database Stack","text":"<p>AgentX uses a hybrid database architecture combining graph, relational, and in-memory databases.</p>"},{"location":"architecture/databases/#overview","title":"Overview","text":"<pre><code>graph TB\n    API[Django API]\n    Neo4j[Neo4j&lt;br/&gt;Graph Database]\n    Postgres[PostgreSQL&lt;br/&gt;+ pgvector]\n    Redis[Redis&lt;br/&gt;Cache]\n\n    API --&gt;|Relationships| Neo4j\n    API --&gt;|Embeddings| Postgres\n    API --&gt;|Cache| Redis\n\n    style Neo4j fill:#4581C3\n    style Postgres fill:#336791\n    style Redis fill:#DC382D</code></pre>"},{"location":"architecture/databases/#database-roles","title":"Database Roles","text":""},{"location":"architecture/databases/#neo4j-graph-database","title":"Neo4j - Graph Database","text":"<p>Purpose: Store and analyze relationships between entities</p> <p>Use Cases:</p> <ul> <li>Entity relationship mapping</li> <li>Knowledge graph construction</li> <li>Semantic connections</li> <li>Graph-based reasoning</li> </ul> <p>Configuration:</p> <ul> <li>Port: 7474 (browser), 7687 (bolt)</li> <li>Data: <code>./data/neo4j/data</code></li> <li>Logs: <code>./data/neo4j/logs</code></li> <li>Plugins: APOC</li> </ul> <p>Example Query:</p> <pre><code>// Create entity with relationships\nCREATE (p:Person {name: 'Alice'})\nCREATE (c:Concept {name: 'Machine Learning'})\nCREATE (p)-[:INTERESTED_IN]-&gt;(c)\n</code></pre>"},{"location":"architecture/databases/#postgresql-pgvector","title":"PostgreSQL + pgvector","text":"<p>Purpose: Store vector embeddings for semantic search</p> <p>Use Cases:</p> <ul> <li>Embedding storage</li> <li>Similarity search</li> <li>Conversation history</li> <li>Structured data</li> </ul> <p>Configuration:</p> <ul> <li>Port: 5432</li> <li>Database: <code>agent_memory</code></li> <li>User: <code>agent</code></li> <li>Data: <code>./data/postgres</code></li> <li>Extensions: pgvector</li> </ul> <p>Example Usage:</p> <pre><code>-- Create embeddings table\nCREATE TABLE embeddings (\n    id SERIAL PRIMARY KEY,\n    content TEXT,\n    embedding vector(768),\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Create vector index\nCREATE INDEX ON embeddings\nUSING ivfflat (embedding vector_cosine_ops);\n\n-- Find similar vectors\nSELECT content,\n       embedding &lt;=&gt; '[0.1, 0.2, ...]' AS distance\nFROM embeddings\nORDER BY distance\nLIMIT 10;\n</code></pre>"},{"location":"architecture/databases/#redis-cache-layer","title":"Redis - Cache Layer","text":"<p>Purpose: High-speed caching and temporary data storage</p> <p>Use Cases:</p> <ul> <li>Translation cache</li> <li>Session storage</li> <li>Rate limiting</li> <li>Real-time data</li> </ul> <p>Configuration:</p> <ul> <li>Port: 6379</li> <li>Data: <code>./data/redis</code></li> <li>Max Memory: 512MB</li> <li>Eviction: allkeys-lru</li> </ul> <p>Example Usage:</p> <pre><code>import redis\n\nr = redis.Redis(host='localhost', port=6379)\n\n# Cache translation\nr.setex('translate:en:fr:hello', 3600, 'bonjour')\n\n# Retrieve cached value\ncached = r.get('translate:en:fr:hello')\n</code></pre>"},{"location":"architecture/databases/#data-flow","title":"Data Flow","text":""},{"location":"architecture/databases/#translation-request","title":"Translation Request","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant API\n    participant Redis\n    participant Model\n    participant Neo4j\n\n    Client-&gt;&gt;API: POST /translate\n    API-&gt;&gt;Redis: Check cache\n\n    alt Cache Hit\n        Redis--&gt;&gt;API: Return cached\n    else Cache Miss\n        API-&gt;&gt;Model: Translate\n        Model--&gt;&gt;API: Result\n        API-&gt;&gt;Redis: Store cache\n        API-&gt;&gt;Neo4j: Store relationship\n    end\n\n    API--&gt;&gt;Client: Translation</code></pre>"},{"location":"architecture/databases/#memory-storage","title":"Memory Storage","text":"<pre><code>sequenceDiagram\n    participant API\n    participant Postgres\n    participant Neo4j\n    participant Redis\n\n    API-&gt;&gt;Postgres: Store embedding\n    API-&gt;&gt;Neo4j: Create relationships\n    API-&gt;&gt;Redis: Cache metadata\n\n    Note over Postgres,Redis: Coordinated storage</code></pre>"},{"location":"architecture/databases/#data-directories","title":"Data Directories","text":"<p>All database data is stored in local bind mounts:</p> <pre><code>data/\n\u251c\u2500\u2500 neo4j/\n\u2502   \u251c\u2500\u2500 data/          # Graph database files\n\u2502   \u251c\u2500\u2500 logs/          # Application logs\n\u2502   \u2514\u2500\u2500 plugins/       # APOC and other plugins\n\u251c\u2500\u2500 postgres/          # PostgreSQL data files\n\u2514\u2500\u2500 redis/             # Redis persistence files\n</code></pre>"},{"location":"architecture/databases/#benefits","title":"Benefits","text":"<ul> <li>Easy Backups: Simple directory copy</li> <li>Portability: Move between environments</li> <li>Debugging: Direct file access</li> <li>No Orphaned Volumes: Explicit data location</li> </ul>"},{"location":"architecture/databases/#migration-from-docker-volumes","title":"Migration from Docker Volumes","text":"<p>If you have existing data in Docker volumes:</p> <pre><code># Migrate all databases\ntask db:migrate-volumes\n\n# Or individually\ntask db:migrate-volumes:neo4j\ntask db:migrate-volumes:postgres\ntask db:migrate-volumes:redis\n</code></pre> <p>This copies data from Docker volumes to <code>./data/</code> directories.</p>"},{"location":"architecture/databases/#backup-strategies","title":"Backup Strategies","text":""},{"location":"architecture/databases/#postgresql-backup","title":"PostgreSQL Backup","text":"<p>Automated backup: <pre><code>task db:backup:postgres\n</code></pre></p> <p>Manual backup: <pre><code>docker exec agent-postgres pg_dump -U agent agent_memory &gt; backup.sql\n</code></pre></p> <p>Restore: <pre><code>task db:restore:postgres BACKUP_FILE=backup.sql\n</code></pre></p>"},{"location":"architecture/databases/#neo4j-backup","title":"Neo4j Backup","text":"<p>Using Neo4j dump: <pre><code>docker exec agent-neo4j neo4j-admin database dump neo4j --to-path=/backups\n</code></pre></p>"},{"location":"architecture/databases/#redis-backup","title":"Redis Backup","text":"<p>Redis automatically persists with AOF: <pre><code># Copy the appendonly.aof file\ncp data/redis/appendonlydir/appendonly.aof.1.base.rdb backups/\n</code></pre></p>"},{"location":"architecture/databases/#full-backup","title":"Full Backup","text":"<p>Copy entire data directory: <pre><code>tar -czf agentx-backup-$(date +%Y%m%d).tar.gz data/\n</code></pre></p>"},{"location":"architecture/databases/#database-maintenance","title":"Database Maintenance","text":""},{"location":"architecture/databases/#postgresql","title":"PostgreSQL","text":"<p>Vacuum and analyze: <pre><code>docker exec agent-postgres psql -U agent -d agent_memory -c \"VACUUM ANALYZE;\"\n</code></pre></p>"},{"location":"architecture/databases/#neo4j","title":"Neo4j","text":"<p>Check database size: <pre><code>CALL dbms.queryJmx(\"org.neo4j:instance=kernel#0,name=Store sizes\")\nYIELD attributes\nRETURN attributes.TotalStoreSize.value AS size\n</code></pre></p>"},{"location":"architecture/databases/#redis","title":"Redis","text":"<p>Get memory stats: <pre><code>docker exec agent-redis redis-cli INFO memory\n</code></pre></p>"},{"location":"architecture/databases/#connection-strings","title":"Connection Strings","text":""},{"location":"architecture/databases/#neo4j_1","title":"Neo4j","text":"<pre><code>bolt://localhost:7687\n</code></pre> <p>Python (neo4j driver): <pre><code>from neo4j import GraphDatabase\n\ndriver = GraphDatabase.driver(\n    \"bolt://localhost:7687\",\n    auth=(\"neo4j\", \"your_secure_password\")\n)\n</code></pre></p>"},{"location":"architecture/databases/#postgresql_1","title":"PostgreSQL","text":"<pre><code>postgresql://agent:your_secure_password@localhost:5432/agent_memory\n</code></pre> <p>Python (psycopg2): <pre><code>import psycopg2\n\nconn = psycopg2.connect(\n    host=\"localhost\",\n    port=5432,\n    database=\"agent_memory\",\n    user=\"agent\",\n    password=\"your_secure_password\"\n)\n</code></pre></p>"},{"location":"architecture/databases/#redis_1","title":"Redis","text":"<pre><code>redis://localhost:6379\n</code></pre> <p>Python (redis-py): <pre><code>import redis\n\nr = redis.Redis(\n    host='localhost',\n    port=6379,\n    decode_responses=True\n)\n</code></pre></p>"},{"location":"architecture/databases/#performance-considerations","title":"Performance Considerations","text":""},{"location":"architecture/databases/#neo4j_2","title":"Neo4j","text":"<ul> <li>Default heap: 512MB initial, 2GB max</li> <li>Page cache: 1GB</li> <li>Increase for larger graphs</li> </ul>"},{"location":"architecture/databases/#postgresql_2","title":"PostgreSQL","text":"<ul> <li>Shared buffers: 25% of RAM</li> <li>Work memory: 4MB per connection</li> <li>Maintenance work memory: 64MB</li> </ul>"},{"location":"architecture/databases/#redis_2","title":"Redis","text":"<ul> <li>Max memory: 512MB (configurable)</li> <li>Eviction policy: allkeys-lru</li> <li>Persistence: AOF enabled</li> </ul>"},{"location":"architecture/databases/#security","title":"Security","text":""},{"location":"architecture/databases/#network-isolation","title":"Network Isolation","text":"<p>Databases are exposed on localhost only. For production:</p> <pre><code># docker-compose.yml\nservices:\n  postgres:\n    ports: []  # Remove port mapping\n    networks:\n      - internal  # Use internal network\n</code></pre>"},{"location":"architecture/databases/#authentication","title":"Authentication","text":"<p>Change default passwords in <code>docker-compose.yml</code>:</p> <pre><code>environment:\n  - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}  # Use env var\n</code></pre>"},{"location":"architecture/databases/#encryption","title":"Encryption","text":"<p>For production, enable:</p> <ul> <li>SSL/TLS for PostgreSQL</li> <li>Bolt encryption for Neo4j</li> <li>Redis AUTH password</li> </ul>"},{"location":"architecture/databases/#monitoring","title":"Monitoring","text":""},{"location":"architecture/databases/#health-checks","title":"Health Checks","text":"<p>All services have built-in health checks:</p> <pre><code>docker ps\n</code></pre> <p>Shows health status for each container.</p>"},{"location":"architecture/databases/#database-shells","title":"Database Shells","text":"<p>Access databases directly:</p> <pre><code># PostgreSQL\ntask db:shell:postgres\n\n# Redis\ntask db:shell:redis\n\n# Neo4j Browser\nopen http://localhost:7474\n</code></pre>"},{"location":"architecture/databases/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/databases/#connection-refused","title":"Connection Refused","text":"<p>Check if services are running: <pre><code>docker-compose ps\n</code></pre></p>"},{"location":"architecture/databases/#data-corruption","title":"Data Corruption","text":"<p>Restore from backup: <pre><code>task db:restore:postgres BACKUP_FILE=backups/latest.sql\n</code></pre></p>"},{"location":"architecture/databases/#disk-space","title":"Disk Space","text":"<p>Check data directory sizes: <pre><code>du -sh data/*\n</code></pre></p>"},{"location":"architecture/databases/#performance-issues","title":"Performance Issues","text":"<p>Check resource usage: <pre><code>docker stats\n</code></pre></p>"},{"location":"architecture/databases/#next-steps","title":"Next Steps","text":"<ul> <li>Database Migration Guide - Data migration strategies</li> <li>API Reference - Database interactions via API</li> <li>Development Tasks - Database management commands</li> </ul>"},{"location":"architecture/memory/","title":"Memory System Architecture","text":"<p>Technical architecture documentation for AgentX's cognitive memory system.</p>"},{"location":"architecture/memory/#system-architecture","title":"System Architecture","text":"<p>The memory system is organized into four layers:</p>"},{"location":"architecture/memory/#1-interface-layer","title":"1. Interface Layer","text":"<ul> <li>AgentMemory - Main unified API</li> <li>Provides high-level operations for storing and retrieving memories</li> <li>Manages coordination between different memory types</li> </ul>"},{"location":"architecture/memory/#2-memory-subsystems","title":"2. Memory Subsystems","text":""},{"location":"architecture/memory/#episodic-memory-memoryepisodicpy","title":"Episodic Memory (<code>memory/episodic.py</code>)","text":"<p>Stores conversation history with full context:</p> <pre><code>class EpisodicMemory:\n    def store_turn(turn: Turn) -&gt; None\n    def store_turn_log(turn: Turn) -&gt; None\n    def vector_search(query_embedding, top_k, user_id, time_window_hours) -&gt; List[Dict]\n    def get_conversation(conversation_id: str) -&gt; List[Turn]\n    def get_recent_turns(user_id, hours, limit) -&gt; List[Dict]\n</code></pre> <p>Storage: - Neo4j: Graph structure with Turn nodes and relationships - PostgreSQL: Audit log and time-series backup</p> <p>Indexing: - Vector index on turn embeddings (1536 dimensions) - BRIN index on timestamps for efficient time-range queries - B-tree index on conversation_id</p>"},{"location":"architecture/memory/#semantic-memory-memorysemanticpy","title":"Semantic Memory (<code>memory/semantic.py</code>)","text":"<p>Manages entities, facts, and conceptual knowledge:</p> <pre><code>class SemanticMemory:\n    def upsert_entity(entity: Entity) -&gt; Entity\n    def store_fact(fact: Fact) -&gt; None\n    def vector_search_facts(query_embedding, top_k, min_confidence) -&gt; List[Dict]\n    def vector_search_entities(query_embedding, top_k) -&gt; List[Dict]\n    def get_entity_graph(entity_ids, depth) -&gt; Dict\n    def create_relationship(source_id, target_id, rel_type, properties) -&gt; None\n</code></pre> <p>Storage: - Neo4j: Entity and Fact nodes with typed relationships - Supports multi-hop graph traversal</p> <p>Key Relationships: - <code>RELATED_TO</code>, <code>PART_OF</code>, <code>LOCATED_IN</code>, <code>WORKS_FOR</code>, <code>KNOWS</code>, <code>CREATED_BY</code>, <code>REFERENCES</code> - <code>DERIVED_FROM</code> (Fact \u2192 Turn) - <code>ABOUT</code> (Fact \u2192 Entity)</p>"},{"location":"architecture/memory/#procedural-memory-memoryproceduralpy","title":"Procedural Memory (<code>memory/procedural.py</code>)","text":"<p>Tracks tool usage and successful strategies:</p> <pre><code>class ProceduralMemory:\n    def record_invocation(conversation_id, turn_id, tool_name, tool_input,\n                         tool_output, success, latency_ms) -&gt; None\n    def learn_strategy(description, context_pattern, tool_sequence,\n                       from_conversation_id, success) -&gt; Strategy\n    def find_strategies(task_description, top_k) -&gt; List[Strategy]\n    def reinforce_strategy(strategy_id, success) -&gt; None\n    def get_tool_stats(task_type) -&gt; List[Dict]\n</code></pre> <p>Storage: - Neo4j: Strategy and Tool nodes with performance metrics - PostgreSQL: Tool invocation audit log</p> <p>Learning Mechanism: - Tracks success/failure counts for strategies - Calculates success rates for recommendation - Links strategies to task types and tool sequences</p>"},{"location":"architecture/memory/#working-memory-memoryworkingpy","title":"Working Memory (<code>memory/working.py</code>)","text":"<p>Fast, ephemeral storage for current session:</p> <pre><code>class WorkingMemory:\n    def add_turn(turn) -&gt; None\n    def get_recent_turns(limit) -&gt; List[Dict]\n    def set(key, value, ttl_seconds) -&gt; None\n    def get(key) -&gt; Optional[Any]\n    def delete(key) -&gt; None\n    def get_context() -&gt; Dict\n    def clear_session() -&gt; None\n    def set_active_goal(goal_id, goal_description) -&gt; None\n    def get_active_goal() -&gt; Optional[Dict]\n    def push_thought(thought) -&gt; None\n    def get_thoughts(limit) -&gt; List[Dict]\n</code></pre> <p>Storage: - Redis lists for turns and thoughts - Redis strings (with TTL) for context values - Automatic expiration after 1 hour (configurable)</p>"},{"location":"architecture/memory/#3-retrieval-layer","title":"3. Retrieval Layer","text":"<p>Multi-strategy retrieval engine combines:</p> <pre><code>class MemoryRetriever:\n    def retrieve(query, user_id, top_k, include_episodic,\n                include_semantic, include_procedural,\n                time_window_hours) -&gt; MemoryBundle\n</code></pre> <p>Strategies: 1. Vector Similarity: Embed query and search each memory type 2. Graph Traversal: Expand from matched entities to related nodes 3. Temporal Filtering: Boost recent memories, filter by time window 4. Reranking: Ensure diversity, limit items per conversation</p> <p>Retrieval Weights: - Episodic: 0.3 - Semantic (Facts): 0.25 - Semantic (Entities): 0.2 - Procedural: 0.15 - Recency: 0.1</p>"},{"location":"architecture/memory/#4-background-processing","title":"4. Background Processing","text":"<p>Consolidation worker runs scheduled jobs:</p> <pre><code>class ConsolidationWorker:\n    jobs = {\n        \"consolidate\": {\"func\": consolidate_episodic_to_semantic, \"interval_minutes\": 15},\n        \"patterns\": {\"func\": detect_patterns, \"interval_minutes\": 60},\n        \"decay\": {\"func\": apply_memory_decay, \"interval_minutes\": 1440},\n        \"cleanup\": {\"func\": cleanup_old_memories, \"interval_minutes\": 1440}\n    }\n</code></pre> <p>Jobs: - consolidate_episodic_to_semantic: Extracts entities and facts from conversations - detect_patterns: Learns strategies from successful conversations - apply_memory_decay: Reduces salience/confidence over time - cleanup_old_memories: Archives old conversations, deletes low-salience entities</p>"},{"location":"architecture/memory/#database-schemas","title":"Database Schemas","text":""},{"location":"architecture/memory/#neo4j-graph-schema","title":"Neo4j Graph Schema","text":""},{"location":"architecture/memory/#node-types","title":"Node Types","text":"<p>Conversation <pre><code>(:Conversation {\n    id: string (unique),\n    started_at: datetime,\n    user_id: string,\n    title: string,\n    consolidated: datetime,\n    patterns_extracted: boolean,\n    archived: boolean\n})\n</code></pre></p> <p>Turn <pre><code>(:Turn {\n    id: string,\n    index: integer,\n    timestamp: datetime,\n    role: string,\n    content: text,\n    embedding: vector(1536),\n    token_count: integer,\n    archived: boolean\n})\n</code></pre></p> <p>Entity <pre><code>(:Entity {\n    id: string (unique),\n    name: string,\n    type: string,\n    aliases: list&lt;string&gt;,\n    description: text,\n    embedding: vector(1536),\n    salience: float,\n    first_seen: datetime,\n    last_accessed: datetime,\n    access_count: integer,\n    properties: map\n})\n</code></pre></p> <p>Fact <pre><code>(:Fact {\n    id: string (unique),\n    claim: text,\n    confidence: float,\n    source: string,\n    source_turn_id: string,\n    embedding: vector(1536),\n    created_at: datetime\n})\n</code></pre></p> <p>Goal <pre><code>(:Goal {\n    id: string (unique),\n    description: text,\n    status: string,\n    priority: integer,\n    created_at: datetime,\n    deadline: datetime,\n    embedding: vector(1536)\n})\n</code></pre></p> <p>Strategy <pre><code>(:Strategy {\n    id: string (unique),\n    description: text,\n    context_pattern: string,\n    tool_sequence: list&lt;string&gt;,\n    embedding: vector(1536),\n    success_count: integer,\n    failure_count: integer,\n    created_at: datetime,\n    last_used: datetime\n})\n</code></pre></p> <p>Tool <pre><code>(:Tool {\n    name: string (unique),\n    usage_count: integer,\n    success_count: integer,\n    avg_latency_ms: float\n})\n</code></pre></p>"},{"location":"architecture/memory/#relationship-types","title":"Relationship Types","text":"<ul> <li><code>(:Conversation)-[:HAS_TURN]-&gt;(:Turn)</code></li> <li><code>(:Turn)-[:FOLLOWED_BY]-&gt;(:Turn)</code></li> <li><code>(:Conversation)-[:MENTIONS]-&gt;(:Entity)</code></li> <li><code>(:Fact)-[:DERIVED_FROM]-&gt;(:Turn)</code></li> <li><code>(:Fact)-[:ABOUT]-&gt;(:Entity)</code></li> <li><code>(:User)-[:HAS_GOAL]-&gt;(:Goal)</code></li> <li><code>(:Goal)-[:SUBGOAL_OF]-&gt;(:Goal)</code></li> <li><code>(:Goal)-[:BLOCKED_BY]-&gt;(:Goal)</code></li> <li><code>(:Strategy)-[:USES_TOOL]-&gt;(:Tool)</code></li> <li><code>(:Strategy)-[:SUCCEEDED_IN]-&gt;(:Conversation)</code></li> <li><code>(:Conversation)-[:USED_TOOL]-&gt;(:ToolInvocation)-[:INVOKED]-&gt;(:Tool)</code></li> </ul>"},{"location":"architecture/memory/#vector-indexes","title":"Vector Indexes","text":"<pre><code>// Turn embeddings (episodic memory)\nCREATE VECTOR INDEX turn_embeddings IF NOT EXISTS\nFOR (t:Turn) ON (t.embedding)\nOPTIONS {indexConfig: {`vector.dimensions`: 1536, `vector.similarity_function`: 'cosine'}};\n\n// Entity embeddings (semantic memory)\nCREATE VECTOR INDEX entity_embeddings IF NOT EXISTS\nFOR (e:Entity) ON (e.embedding)\nOPTIONS {indexConfig: {`vector.dimensions`: 1536, `vector.similarity_function`: 'cosine'}};\n\n// Fact embeddings\nCREATE VECTOR INDEX fact_embeddings IF NOT EXISTS\nFOR (f:Fact) ON (f.embedding)\nOPTIONS {indexConfig: {`vector.dimensions`: 1536, `vector.similarity_function`: 'cosine'}};\n\n// Strategy embeddings (procedural memory)\nCREATE VECTOR INDEX strategy_embeddings IF NOT EXISTS\nFOR (s:Strategy) ON (s.embedding)\nOPTIONS {indexConfig: {`vector.dimensions`: 1536, `vector.similarity_function`: 'cosine'}};\n</code></pre>"},{"location":"architecture/memory/#postgresql-schema","title":"PostgreSQL Schema","text":""},{"location":"architecture/memory/#conversation_logs","title":"conversation_logs","text":"<pre><code>CREATE TABLE conversation_logs (\n    id BIGSERIAL PRIMARY KEY,\n    conversation_id UUID NOT NULL,\n    turn_index INTEGER NOT NULL,\n    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    role VARCHAR(20) NOT NULL,\n    content TEXT NOT NULL,\n    content_hash VARCHAR(64),\n    token_count INTEGER,\n    model VARCHAR(100),\n    metadata JSONB DEFAULT '{}',\n    embedding vector(1536),\n    UNIQUE(conversation_id, turn_index)\n);\n\nCREATE INDEX idx_logs_timestamp ON conversation_logs USING BRIN (timestamp);\nCREATE INDEX idx_logs_conversation ON conversation_logs (conversation_id);\nCREATE INDEX idx_logs_embedding ON conversation_logs USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);\n</code></pre>"},{"location":"architecture/memory/#memory_timeline","title":"memory_timeline","text":"<pre><code>CREATE TABLE memory_timeline (\n    id BIGSERIAL PRIMARY KEY,\n    memory_type VARCHAR(50) NOT NULL,\n    neo4j_node_id VARCHAR(100),\n    event_time TIMESTAMPTZ NOT NULL,\n    summary TEXT,\n    embedding vector(1536),\n    importance_score FLOAT DEFAULT 0.5,\n    access_count INTEGER DEFAULT 0,\n    last_accessed TIMESTAMPTZ,\n    archived BOOLEAN DEFAULT FALSE,\n    metadata JSONB DEFAULT '{}'\n);\n\nCREATE INDEX idx_timeline_time ON memory_timeline USING BRIN (event_time);\nCREATE INDEX idx_timeline_type ON memory_timeline (memory_type);\nCREATE INDEX idx_timeline_importance ON memory_timeline (importance_score DESC);\nCREATE INDEX idx_timeline_embedding ON memory_timeline USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);\n</code></pre>"},{"location":"architecture/memory/#tool_invocations","title":"tool_invocations","text":"<pre><code>CREATE TABLE tool_invocations (\n    id BIGSERIAL PRIMARY KEY,\n    conversation_id UUID NOT NULL,\n    turn_index INTEGER NOT NULL,\n    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    tool_name VARCHAR(100) NOT NULL,\n    tool_input JSONB NOT NULL,\n    tool_output JSONB,\n    success BOOLEAN,\n    latency_ms INTEGER,\n    error_message TEXT\n);\n\nCREATE INDEX idx_tools_conversation ON tool_invocations (conversation_id);\nCREATE INDEX idx_tools_name ON tool_invocations (tool_name);\nCREATE INDEX idx_tools_timestamp ON tool_invocations USING BRIN (timestamp);\n</code></pre>"},{"location":"architecture/memory/#user_profiles","title":"user_profiles","text":"<pre><code>CREATE TABLE user_profiles (\n    user_id VARCHAR(100) PRIMARY KEY,\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    updated_at TIMESTAMPTZ DEFAULT NOW(),\n    preferences JSONB DEFAULT '{}',\n    expertise_areas JSONB DEFAULT '[]',\n    communication_style JSONB DEFAULT '{}',\n    metadata JSONB DEFAULT '{}'\n);\n</code></pre>"},{"location":"architecture/memory/#data-flow","title":"Data Flow","text":""},{"location":"architecture/memory/#1-storing-a-conversation-turn","title":"1. Storing a Conversation Turn","text":"<pre><code>User Input \u2192 AgentMemory.store_turn()\n    \u251c\u2500\u2192 Generate embedding (if missing)\n    \u251c\u2500\u2192 EpisodicMemory.store_turn() \u2192 Neo4j (graph structure)\n    \u251c\u2500\u2192 EpisodicMemory.store_turn_log() \u2192 PostgreSQL (audit log)\n    \u2514\u2500\u2192 WorkingMemory.add_turn() \u2192 Redis (session cache)\n</code></pre>"},{"location":"architecture/memory/#2-memory-retrieval","title":"2. Memory Retrieval","text":"<pre><code>Query \u2192 AgentMemory.remember()\n    \u2514\u2500\u2192 MemoryRetriever.retrieve()\n        \u251c\u2500\u2192 Generate query embedding\n        \u251c\u2500\u2192 EpisodicMemory.vector_search() \u2192 relevant turns\n        \u251c\u2500\u2192 SemanticMemory.vector_search_facts() \u2192 relevant facts\n        \u251c\u2500\u2192 SemanticMemory.vector_search_entities() \u2192 relevant entities\n        \u2502   \u2514\u2500\u2192 SemanticMemory.get_entity_graph() \u2192 expand to related\n        \u251c\u2500\u2192 ProceduralMemory.find_strategies() \u2192 applicable strategies\n        \u251c\u2500\u2192 Get active goals and user context\n        \u2514\u2500\u2192 Rerank and return MemoryBundle\n</code></pre>"},{"location":"architecture/memory/#3-background-consolidation","title":"3. Background Consolidation","text":"<pre><code>ConsolidationWorker (every 15 min)\n    \u2514\u2500\u2192 consolidate_episodic_to_semantic()\n        \u251c\u2500\u2192 Query unconsolidated conversations\n        \u251c\u2500\u2192 Extract entities \u2192 SemanticMemory.upsert_entity()\n        \u251c\u2500\u2192 Extract facts \u2192 SemanticMemory.store_fact()\n        \u2514\u2500\u2192 Mark conversation as consolidated\n</code></pre>"},{"location":"architecture/memory/#memory-decay","title":"Memory Decay","text":"<p>Implements forgetting curve based on:</p> <ul> <li>Time since last access: Exponential decay</li> <li>Access frequency: Logarithmic boost</li> <li>Recency: Inverse exponential boost</li> </ul> <pre><code># Exponential decay formula\ndecayed_value = initial_value * (decay_rate ** days_since_access)\n\n# Default decay rate: 0.95 (5% daily decay)\n# Half-life \u2248 14 days\n</code></pre> <p>Decay Targets: - Entity salience: Daily decay for entities not accessed in 24h - Fact confidence: Weekly decay for inferred facts (slower decay)</p>"},{"location":"architecture/memory/#performance-considerations","title":"Performance Considerations","text":""},{"location":"architecture/memory/#vector-search-optimization","title":"Vector Search Optimization","text":"<ul> <li>Use ANN (Approximate Nearest Neighbors) with IVFFlat index</li> <li>Over-fetch (2x top_k) to account for filtering</li> <li>Cache embeddings for frequently accessed items</li> </ul>"},{"location":"architecture/memory/#graph-traversal-limits","title":"Graph Traversal Limits","text":"<ul> <li>Limit depth to 2-3 hops to prevent slow queries</li> <li>Use <code>LIMIT</code> clauses in all Cypher queries</li> <li>Consider materialized paths for deep hierarchies</li> </ul>"},{"location":"architecture/memory/#redis-memory-management","title":"Redis Memory Management","text":"<ul> <li>Use TTLs on all working memory keys</li> <li>Configure LRU eviction policy: <code>maxmemory-policy allkeys-lru</code></li> <li>Monitor memory usage with <code>INFO memory</code></li> </ul>"},{"location":"architecture/memory/#postgresql-time-series-optimization","title":"PostgreSQL Time-Series Optimization","text":"<ul> <li>BRIN indexes for timestamp columns (highly efficient for time-series)</li> <li>Partition large tables by time range</li> <li>Use <code>EXPLAIN ANALYZE</code> to optimize slow queries</li> </ul>"},{"location":"architecture/memory/#scaling-considerations","title":"Scaling Considerations","text":""},{"location":"architecture/memory/#horizontal-scaling","title":"Horizontal Scaling","text":"<ul> <li>Neo4j: Use Neo4j Enterprise with clustering (read replicas)</li> <li>PostgreSQL: Use read replicas for analytics queries</li> <li>Redis: Use Redis Cluster for distributed caching</li> </ul>"},{"location":"architecture/memory/#vertical-scaling","title":"Vertical Scaling","text":"<ul> <li>Neo4j: Allocate 2-4GB heap, 1GB+ page cache</li> <li>PostgreSQL: Tune <code>shared_buffers</code>, <code>work_mem</code>, <code>effective_cache_size</code></li> <li>Redis: Allocate 512MB-2GB depending on working memory size</li> </ul>"},{"location":"architecture/memory/#data-retention","title":"Data Retention","text":"<ul> <li>Archive conversations older than 90 days (configurable)</li> <li>Delete entities with salience &lt; 0.1 not accessed in 30 days</li> <li>Keep audit logs in PostgreSQL for compliance (longer retention)</li> </ul>"},{"location":"architecture/memory/#security-considerations","title":"Security Considerations","text":"<ul> <li>Store embeddings in vector format (not reversible to text)</li> <li>Encrypt sensitive data in PostgreSQL</li> <li>Use connection pooling to prevent exhaustion</li> <li>Implement rate limiting on retrieval operations</li> <li>Sanitize user input to prevent Cypher injection</li> </ul>"},{"location":"architecture/memory/#monitoring","title":"Monitoring","text":"<p>Key metrics to track:</p> <ul> <li>Memory size: Total nodes/relationships in Neo4j</li> <li>Query performance: P50, P95, P99 latencies for retrieval</li> <li>Consolidation lag: Time between conversation end and consolidation</li> <li>Cache hit rate: Redis cache effectiveness</li> <li>Decay rate: Number of entities/facts decayed per day</li> </ul>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>AgentX follows a two-tier architecture with clear separation between API and client layers.</p>"},{"location":"architecture/overview/#system-architecture","title":"System Architecture","text":"<pre><code>graph TB\n    subgraph \"Client Layer\"\n        Tauri[Tauri v2 Desktop App]\n        React[React 19 + TypeScript]\n        Vite[Vite Build System]\n    end\n\n    subgraph \"API Layer\"\n        Django[Django 5.2.8 REST API]\n        ML[HuggingFace Transformers]\n    end\n\n    subgraph \"Data Layer\"\n        Neo4j[Neo4j Graph DB]\n        Postgres[PostgreSQL + pgvector]\n        Redis[Redis Cache]\n    end\n\n    React --&gt; Tauri\n    Tauri --&gt;|HTTP| Django\n    Django --&gt; ML\n    Django --&gt; Neo4j\n    Django --&gt; Postgres\n    Django --&gt; Redis</code></pre>"},{"location":"architecture/overview/#core-components","title":"Core Components","text":"<ul> <li>Client Layer: Desktop application built with Tauri and React</li> <li>API Layer: Django REST API providing AI services</li> <li>Data Layer: Multi-database stack for different use cases</li> </ul> <p>See API Layer, Client Layer, and Database Stack for details.</p>"},{"location":"deployment/docker/","title":"Docker Deployment","text":"<p>Deploying AgentX with Docker.</p>"},{"location":"deployment/docker/#docker-compose","title":"Docker Compose","text":"<p>The project uses Docker Compose for database services:</p> <pre><code># Start services\ndocker-compose up -d\n\n# Stop services\ndocker-compose down\n\n# View logs\ndocker-compose logs -f\n</code></pre>"},{"location":"deployment/docker/#services","title":"Services","text":"<ul> <li>Neo4j: Graph database</li> <li>PostgreSQL: Relational database with pgvector</li> <li>Redis: Cache layer</li> </ul> <p>See docker-compose.yml for configuration.</p>"},{"location":"deployment/docker/#production-considerations","title":"Production Considerations","text":"<ul> <li>Change default passwords</li> <li>Use environment variables</li> <li>Configure backups</li> <li>Set up monitoring</li> <li>Enable SSL/TLS</li> </ul>"},{"location":"deployment/migration/","title":"Database Migration","text":"<p>Guide for migrating database data.</p>"},{"location":"deployment/migration/#from-docker-volumes-to-bind-mounts","title":"From Docker Volumes to Bind Mounts","text":"<pre><code># Migrate all databases\ntask db:migrate-volumes\n\n# Or individually\ntask db:migrate-volumes:neo4j\ntask db:migrate-volumes:postgres\ntask db:migrate-volumes:redis\n</code></pre>"},{"location":"deployment/migration/#backup-and-restore","title":"Backup and Restore","text":""},{"location":"deployment/migration/#postgresql","title":"PostgreSQL","text":"<p>Backup: <pre><code>task db:backup:postgres\n</code></pre></p> <p>Restore: <pre><code>task db:restore:postgres BACKUP_FILE=backups/postgres_20231127.sql\n</code></pre></p>"},{"location":"deployment/migration/#data-directories","title":"Data Directories","text":"<p>All data stored in <code>./data/</code>:</p> <pre><code>data/\n\u251c\u2500\u2500 neo4j/\n\u251c\u2500\u2500 postgres/\n\u2514\u2500\u2500 redis/\n</code></pre> <p>See Database Stack for details.</p>"},{"location":"development/contributing/","title":"Contributing","text":"<p>Thank you for contributing to AgentX!</p>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository</li> <li>Clone your fork</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Run tests</li> <li>Submit a pull request</li> </ol>"},{"location":"development/contributing/#development-guidelines","title":"Development Guidelines","text":"<ul> <li>Follow existing code style</li> <li>Write tests for new features</li> <li>Update documentation</li> <li>Keep commits atomic and meaningful</li> </ul>"},{"location":"development/contributing/#code-review-process","title":"Code Review Process","text":"<p>All changes require code review before merging.</p>"},{"location":"development/contributing/#questions","title":"Questions?","text":"<p>Open an issue or discussion on GitHub.</p>"},{"location":"development/memory-setup/","title":"Memory System Setup Guide","text":"<p>Complete setup instructions for the AgentX memory system.</p>"},{"location":"development/memory-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker and Docker Compose (for containerized databases)</li> <li>Python 3.11+ with uv or pip</li> <li>OpenAI API key (for embeddings) or local model setup</li> </ul>"},{"location":"development/memory-setup/#quick-start","title":"Quick Start","text":""},{"location":"development/memory-setup/#1-start-database-services","title":"1. Start Database Services","text":"<p>Use the provided Docker Compose configuration:</p> <pre><code># Start all database services\ndocker-compose up -d\n\n# Verify services are running\ndocker-compose ps\n\n# Check logs\ndocker-compose logs -f neo4j postgres redis\n</code></pre>"},{"location":"development/memory-setup/#2-initialize-neo4j-schema","title":"2. Initialize Neo4j Schema","text":"<p>Run the schema initialization script:</p> <pre><code># Connect to Neo4j browser\nopen http://localhost:7474\n\n# Or use cypher-shell\ndocker exec -it agent-neo4j cypher-shell -u neo4j -p your_secure_password\n</code></pre> <p>Execute the following Cypher commands:</p> <pre><code>// ============================================\n// CONSTRAINTS AND INDEXES\n// ============================================\n\n// Uniqueness constraints\nCREATE CONSTRAINT conversation_id IF NOT EXISTS\nFOR (c:Conversation) REQUIRE c.id IS UNIQUE;\n\nCREATE CONSTRAINT entity_id IF NOT EXISTS\nFOR (e:Entity) REQUIRE e.id IS UNIQUE;\n\nCREATE CONSTRAINT fact_id IF NOT EXISTS\nFOR (f:Fact) REQUIRE f.id IS UNIQUE;\n\nCREATE CONSTRAINT goal_id IF NOT EXISTS\nFOR (g:Goal) REQUIRE g.id IS UNIQUE;\n\nCREATE CONSTRAINT user_id IF NOT EXISTS\nFOR (u:User) REQUIRE u.id IS UNIQUE;\n\n// Property indexes for fast lookups\nCREATE INDEX entity_name IF NOT EXISTS FOR (e:Entity) ON (e.name);\nCREATE INDEX entity_type IF NOT EXISTS FOR (e:Entity) ON (e.type);\nCREATE INDEX fact_confidence IF NOT EXISTS FOR (f:Fact) ON (f.confidence);\nCREATE INDEX goal_status IF NOT EXISTS FOR (g:Goal) ON (g.status);\nCREATE INDEX turn_timestamp IF NOT EXISTS FOR (t:Turn) ON (t.timestamp);\n\n// Full-text search indexes\nCREATE FULLTEXT INDEX entity_search IF NOT EXISTS\nFOR (e:Entity) ON EACH [e.name, e.aliases, e.description];\n\nCREATE FULLTEXT INDEX fact_search IF NOT EXISTS\nFOR (f:Fact) ON EACH [f.claim];\n\n// ============================================\n// VECTOR INDEXES\n// ============================================\n\n// Turn embeddings (episodic memory)\nCREATE VECTOR INDEX turn_embeddings IF NOT EXISTS\nFOR (t:Turn) ON (t.embedding)\nOPTIONS {\n    indexConfig: {\n        `vector.dimensions`: 1536,\n        `vector.similarity_function`: 'cosine'\n    }\n};\n\n// Entity embeddings (semantic memory)\nCREATE VECTOR INDEX entity_embeddings IF NOT EXISTS\nFOR (e:Entity) ON (e.embedding)\nOPTIONS {\n    indexConfig: {\n        `vector.dimensions`: 1536,\n        `vector.similarity_function`: 'cosine'\n    }\n};\n\n// Fact embeddings\nCREATE VECTOR INDEX fact_embeddings IF NOT EXISTS\nFOR (f:Fact) ON (f.embedding)\nOPTIONS {\n    indexConfig: {\n        `vector.dimensions`: 1536,\n        `vector.similarity_function`: 'cosine'\n    }\n};\n\n// Strategy embeddings (procedural memory)\nCREATE VECTOR INDEX strategy_embeddings IF NOT EXISTS\nFOR (s:Strategy) ON (s.embedding)\nOPTIONS {\n    indexConfig: {\n        `vector.dimensions`: 1536,\n        `vector.similarity_function`: 'cosine'\n    }\n};\n</code></pre>"},{"location":"development/memory-setup/#3-initialize-postgresql-schema","title":"3. Initialize PostgreSQL Schema","text":"<p>Connect to PostgreSQL and run the initialization script:</p> <pre><code># Connect to PostgreSQL\ndocker exec -it agent-postgres psql -U agent -d agent_memory\n\n# Or use a SQL file\ndocker exec -i agent-postgres psql -U agent -d agent_memory &lt; init-scripts/01-init.sql\n</code></pre> <p>SQL initialization script:</p> <pre><code>-- Enable pgvector extension\nCREATE EXTENSION IF NOT EXISTS vector;\nCREATE EXTENSION IF NOT EXISTS pg_trgm;  -- For fuzzy text search\n\n-- Conversation logs (append-only time series)\nCREATE TABLE conversation_logs (\n    id BIGSERIAL PRIMARY KEY,\n    conversation_id UUID NOT NULL,\n    turn_index INTEGER NOT NULL,\n    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    role VARCHAR(20) NOT NULL,\n    content TEXT NOT NULL,\n    content_hash VARCHAR(64),\n    token_count INTEGER,\n    model VARCHAR(100),\n    metadata JSONB DEFAULT '{}',\n    embedding vector(1536),\n\n    UNIQUE(conversation_id, turn_index)\n);\n\n-- BRIN index for time-range queries (very efficient for time-series)\nCREATE INDEX idx_logs_timestamp ON conversation_logs USING BRIN (timestamp);\nCREATE INDEX idx_logs_conversation ON conversation_logs (conversation_id);\nCREATE INDEX idx_logs_embedding ON conversation_logs USING ivfflat (embedding vector_cosine_ops)\n    WITH (lists = 100);\n\n-- Memory timeline (unified temporal index)\nCREATE TABLE memory_timeline (\n    id BIGSERIAL PRIMARY KEY,\n    memory_type VARCHAR(50) NOT NULL,\n    neo4j_node_id VARCHAR(100),\n    event_time TIMESTAMPTZ NOT NULL,\n    summary TEXT,\n    embedding vector(1536),\n    importance_score FLOAT DEFAULT 0.5,\n    access_count INTEGER DEFAULT 0,\n    last_accessed TIMESTAMPTZ,\n    archived BOOLEAN DEFAULT FALSE,\n    metadata JSONB DEFAULT '{}'\n);\n\nCREATE INDEX idx_timeline_time ON memory_timeline USING BRIN (event_time);\nCREATE INDEX idx_timeline_type ON memory_timeline (memory_type);\nCREATE INDEX idx_timeline_importance ON memory_timeline (importance_score DESC);\nCREATE INDEX idx_timeline_embedding ON memory_timeline USING ivfflat (embedding vector_cosine_ops)\n    WITH (lists = 100);\n\n-- Tool invocations audit\nCREATE TABLE tool_invocations (\n    id BIGSERIAL PRIMARY KEY,\n    conversation_id UUID NOT NULL,\n    turn_index INTEGER NOT NULL,\n    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    tool_name VARCHAR(100) NOT NULL,\n    tool_input JSONB NOT NULL,\n    tool_output JSONB,\n    success BOOLEAN,\n    latency_ms INTEGER,\n    error_message TEXT\n);\n\nCREATE INDEX idx_tools_conversation ON tool_invocations (conversation_id);\nCREATE INDEX idx_tools_name ON tool_invocations (tool_name);\nCREATE INDEX idx_tools_timestamp ON tool_invocations USING BRIN (timestamp);\n\n-- User preferences and profiles\nCREATE TABLE user_profiles (\n    user_id VARCHAR(100) PRIMARY KEY,\n    created_at TIMESTAMPTZ DEFAULT NOW(),\n    updated_at TIMESTAMPTZ DEFAULT NOW(),\n    preferences JSONB DEFAULT '{}',\n    expertise_areas JSONB DEFAULT '[]',\n    communication_style JSONB DEFAULT '{}',\n    metadata JSONB DEFAULT '{}'\n);\n\n-- Function to update timestamp\nCREATE OR REPLACE FUNCTION update_updated_at()\nRETURNS TRIGGER AS $$\nBEGIN\n    NEW.updated_at = NOW();\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER user_profiles_updated\n    BEFORE UPDATE ON user_profiles\n    FOR EACH ROW\n    EXECUTE FUNCTION update_updated_at();\n</code></pre>"},{"location":"development/memory-setup/#4-configure-environment-variables","title":"4. Configure Environment Variables","text":"<p>Create a <code>.env</code> file in the project root:</p> <pre><code># Neo4j Configuration\nNEO4J_URI=bolt://localhost:7687\nNEO4J_USER=neo4j\nNEO4J_PASSWORD=your_secure_password\n\n# PostgreSQL Configuration\nPOSTGRES_URI=postgresql://agent:your_secure_password@localhost:5432/agent_memory\n\n# Redis Configuration\nREDIS_URI=redis://localhost:6379\n\n# Embedding Provider\nEMBEDDING_PROVIDER=openai  # or \"local\"\nEMBEDDING_MODEL=text-embedding-3-small\nEMBEDDING_DIMENSIONS=1536\nOPENAI_API_KEY=sk-your-api-key-here\n\n# Local Embedding Model (if using local)\nLOCAL_EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5\n\n# Memory Settings\nEPISODIC_RETENTION_DAYS=90\nFACT_CONFIDENCE_THRESHOLD=0.7\nSALIENCE_DECAY_RATE=0.95\nMAX_WORKING_MEMORY_ITEMS=50\n\n# Retrieval Settings\nDEFAULT_TOP_K=10\nRERANKING_ENABLED=true\n</code></pre>"},{"location":"development/memory-setup/#5-install-python-dependencies","title":"5. Install Python Dependencies","text":"<p>Add required dependencies to your project:</p> <pre><code># Using uv (recommended)\nuv add neo4j redis sqlalchemy psycopg2-binary pgvector pydantic-settings\n\n# For OpenAI embeddings\nuv add openai\n\n# For local embeddings\nuv add sentence-transformers\n\n# Optional: for entity extraction\nuv add spacy\npython -m spacy download en_core_web_sm\n</code></pre> <p>Or add to <code>pyproject.toml</code>:</p> <pre><code>[project]\ndependencies = [\n    \"neo4j&gt;=5.15.0\",\n    \"redis&gt;=5.0.0\",\n    \"sqlalchemy&gt;=2.0.0\",\n    \"psycopg2-binary&gt;=2.9.0\",\n    \"pgvector&gt;=0.2.0\",\n    \"pydantic-settings&gt;=2.0.0\",\n    \"openai&gt;=1.0.0\",  # For OpenAI embeddings\n    \"sentence-transformers&gt;=2.2.0\",  # For local embeddings\n]\n</code></pre>"},{"location":"development/memory-setup/#6-verify-installation","title":"6. Verify Installation","text":"<p>Test the memory system:</p> <pre><code>from agentx_ai.kit.agent_memory import AgentMemory, Turn\nfrom uuid import uuid4\n\n# Initialize memory\nmemory = AgentMemory(user_id=\"test_user\", conversation_id=str(uuid4()))\n\n# Store a test turn\nturn = Turn(\n    conversation_id=memory.conversation_id,\n    index=0,\n    role=\"user\",\n    content=\"Hello, this is a test message.\"\n)\nmemory.store_turn(turn)\n\n# Retrieve\ncontext = memory.remember(\"test message\")\nprint(context.to_context_string())\n\n# Clean up\nmemory.close()\n</code></pre>"},{"location":"development/memory-setup/#running-the-consolidation-worker","title":"Running the Consolidation Worker","text":"<p>The background consolidation worker should run as a separate process:</p> <pre><code># Development\npython -m agentx_ai.kit.agent_memory.consolidation.worker\n\n# Production (with supervisor/systemd)\n# See deployment section below\n</code></pre>"},{"location":"development/memory-setup/#docker-compose-configuration","title":"Docker Compose Configuration","text":"<p>Create <code>docker-compose.yml</code> for the memory system databases:</p> <pre><code>version: '3.8'\n\nservices:\n  neo4j:\n    image: neo4j:5.15-community\n    container_name: agent-neo4j\n    ports:\n      - \"7474:7474\"  # Browser\n      - \"7687:7687\"  # Bolt\n    environment:\n      - NEO4J_AUTH=neo4j/your_secure_password\n      - NEO4J_PLUGINS=[\"apoc\"]\n      - NEO4J_apoc_export_file_enabled=true\n      - NEO4J_apoc_import_file_enabled=true\n      - NEO4J_apoc_import_file_use__neo4j__config=true\n      - NEO4J_server_memory_heap_initial__size=512m\n      - NEO4J_server_memory_heap_max__size=2G\n      - NEO4J_server_memory_pagecache_size=1G\n    volumes:\n      - ./data/neo4j/data:/data\n      - ./data/neo4j/logs:/logs\n      - ./data/neo4j/plugins:/plugins\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:7474\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  postgres:\n    image: pgvector/pgvector:pg16\n    container_name: agent-postgres\n    ports:\n      - \"5432:5432\"\n    environment:\n      - POSTGRES_USER=agent\n      - POSTGRES_PASSWORD=your_secure_password\n      - POSTGRES_DB=agent_memory\n    volumes:\n      - ./data/postgres:/var/lib/postgresql/data\n      - ./init-scripts:/docker-entrypoint-initdb.d\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U agent -d agent_memory\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  redis:\n    image: redis:7-alpine\n    container_name: agent-redis\n    ports:\n      - \"6379:6379\"\n    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru\n    volumes:\n      - ./data/redis:/data\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Optional: Redis GUI\n  redis-commander:\n    image: rediscommander/redis-commander:latest\n    container_name: agent-redis-gui\n    ports:\n      - \"8081:8081\"\n    environment:\n      - REDIS_HOSTS=local:redis:6379\n    depends_on:\n      - redis\n</code></pre>"},{"location":"development/memory-setup/#development-workflow","title":"Development Workflow","text":""},{"location":"development/memory-setup/#testing-memory-operations","title":"Testing Memory Operations","text":"<pre><code># Test episodic memory\nfrom agentx_ai.kit.agent_memory import AgentMemory, Turn\nfrom uuid import uuid4\n\nmemory = AgentMemory(user_id=\"dev_user\", conversation_id=str(uuid4()))\n\n# Add multiple turns\nfor i, content in enumerate([\"Hello\", \"How are you?\", \"Tell me about Python\"]):\n    turn = Turn(\n        conversation_id=memory.conversation_id,\n        index=i,\n        role=\"user\" if i % 2 == 0 else \"assistant\",\n        content=content\n    )\n    memory.store_turn(turn)\n\n# Test retrieval\ncontext = memory.remember(\"Python programming\", top_k=5)\nprint(f\"Found {len(context.relevant_turns)} relevant turns\")\n\n# Test semantic memory\nfrom agentx_ai.kit.agent_memory import Entity\n\nentity = Entity(\n    name=\"Python\",\n    type=\"ProgrammingLanguage\",\n    description=\"High-level programming language\"\n)\nmemory.upsert_entity(entity)\n\n# Test procedural memory\nmemory.record_tool_usage(\n    tool_name=\"code_interpreter\",\n    tool_input={\"code\": \"print('hello')\"},\n    tool_output={\"result\": \"hello\"},\n    success=True,\n    latency_ms=150\n)\n</code></pre>"},{"location":"development/memory-setup/#monitoring","title":"Monitoring","text":"<p>Check database health:</p> <pre><code># Neo4j stats\ndocker exec agent-neo4j cypher-shell -u neo4j -p password \"CALL dbms.listConfig() YIELD name, value WHERE name STARTS WITH 'dbms.memory' RETURN name, value\"\n\n# PostgreSQL stats\ndocker exec agent-postgres psql -U agent -d agent_memory -c \"SELECT schemaname, tablename, pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size FROM pg_tables WHERE schemaname NOT IN ('pg_catalog', 'information_schema') ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;\"\n\n# Redis stats\ndocker exec agent-redis redis-cli INFO memory\n</code></pre>"},{"location":"development/memory-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/memory-setup/#neo4j-connection-issues","title":"Neo4j Connection Issues","text":"<pre><code># Check if Neo4j is running\ndocker ps | grep neo4j\n\n# Check logs\ndocker logs agent-neo4j\n\n# Test connection\ndocker exec agent-neo4j cypher-shell -u neo4j -p password \"RETURN 'Connected' as status\"\n</code></pre>"},{"location":"development/memory-setup/#postgresql-connection-issues","title":"PostgreSQL Connection Issues","text":"<pre><code># Check if PostgreSQL is running\ndocker ps | grep postgres\n\n# Check logs\ndocker logs agent-postgres\n\n# Test connection\ndocker exec agent-postgres pg_isready -U agent -d agent_memory\n</code></pre>"},{"location":"development/memory-setup/#redis-connection-issues","title":"Redis Connection Issues","text":"<pre><code># Check if Redis is running\ndocker ps | grep redis\n\n# Test connection\ndocker exec agent-redis redis-cli ping\n</code></pre>"},{"location":"development/memory-setup/#vector-index-issues","title":"Vector Index Issues","text":"<p>If vector searches are slow:</p> <pre><code>// Check vector index status\nSHOW INDEXES YIELD name, type, state WHERE type = \"VECTOR\";\n\n// Rebuild vector index if needed\nDROP INDEX turn_embeddings;\nCREATE VECTOR INDEX turn_embeddings FOR (t:Turn) ON (t.embedding)\nOPTIONS {indexConfig: {`vector.dimensions`: 1536, `vector.similarity_function`: 'cosine'}};\n</code></pre>"},{"location":"development/memory-setup/#production-deployment","title":"Production Deployment","text":""},{"location":"development/memory-setup/#using-supervisor","title":"Using Supervisor","text":"<p>Create <code>/etc/supervisor/conf.d/agentx-memory-worker.conf</code>:</p> <pre><code>[program:agentx-memory-worker]\ncommand=/path/to/venv/bin/python -m agentx_ai.kit.agent_memory.consolidation.worker\ndirectory=/path/to/agentx-source\nuser=agentx\nautostart=true\nautorestart=true\nstderr_logfile=/var/log/agentx/memory-worker.err.log\nstdout_logfile=/var/log/agentx/memory-worker.out.log\nenvironment=PATH=\"/path/to/venv/bin\"\n</code></pre>"},{"location":"development/memory-setup/#using-systemd","title":"Using Systemd","text":"<p>Create <code>/etc/systemd/system/agentx-memory-worker.service</code>:</p> <pre><code>[Unit]\nDescription=AgentX Memory Consolidation Worker\nAfter=network.target\n\n[Service]\nType=simple\nUser=agentx\nWorkingDirectory=/path/to/agentx-source\nEnvironment=\"PATH=/path/to/venv/bin\"\nExecStart=/path/to/venv/bin/python -m agentx_ai.kit.agent_memory.consolidation.worker\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Then:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable agentx-memory-worker\nsudo systemctl start agentx-memory-worker\nsudo systemctl status agentx-memory-worker\n</code></pre>"},{"location":"development/memory-setup/#next-steps","title":"Next Steps","text":"<ol> <li>Implement entity extraction (see <code>extraction/entities.py</code>)</li> <li>Implement fact extraction (see <code>extraction/facts.py</code>)</li> <li>Configure monitoring and alerting</li> <li>Set up backup procedures for databases</li> <li>Tune database parameters for your workload</li> </ol>"},{"location":"development/memory-setup/#related-documentation","title":"Related Documentation","text":"<ul> <li>Memory System Overview</li> <li>Memory Architecture</li> <li>Database Stack</li> </ul>"},{"location":"development/setup/","title":"Development Setup","text":"<p>Set up your development environment for contributing to AgentX.</p>"},{"location":"development/setup/#prerequisites","title":"Prerequisites","text":"<p>Install required tools:</p> <ul> <li>Python 3.10+ with uv</li> <li>Node.js 18+ with bun</li> <li>Docker &amp; Docker Compose</li> <li>Task runner</li> <li>Git</li> </ul> <p>See Installation for details.</p>"},{"location":"development/setup/#initial-setup","title":"Initial Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/yourusername/agentx-source.git\ncd agentx-source\n\n# Install dependencies\ntask install\n\n# Initialize databases\ntask db:init\n\n# Start development environment\ntask dev\n</code></pre>"},{"location":"development/setup/#development-workflow","title":"Development Workflow","text":"<ol> <li>Create feature branch</li> <li>Make changes with hot reload</li> <li>Run tests</li> <li>Commit and push</li> <li>Create pull request</li> </ol> <p>See Contributing Guide for detailed workflow.</p>"},{"location":"development/tasks/","title":"Task Commands","text":"<p>Complete reference for Taskfile automation commands.</p>"},{"location":"development/tasks/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"development/tasks/#install-all-dependencies","title":"Install All Dependencies","text":"<pre><code>task install\n</code></pre> <p>Runs <code>uv sync</code> and <code>bun install</code> to install all dependencies.</p>"},{"location":"development/tasks/#initialize-databases","title":"Initialize Databases","text":"<pre><code>task db:init\n</code></pre> <p>Creates data directories for Neo4j, PostgreSQL, and Redis.</p>"},{"location":"development/tasks/#development","title":"Development","text":""},{"location":"development/tasks/#start-development-environment","title":"Start Development Environment","text":"<pre><code>task dev\n</code></pre> <p>Starts all services:</p> <ul> <li>Docker containers (Neo4j, Postgres, Redis)</li> <li>Django API on port 12319</li> <li>Tauri development window</li> </ul>"},{"location":"development/tasks/#start-services-only","title":"Start Services Only","text":"<pre><code>task runners\n</code></pre> <p>Starts Docker containers without API or client.</p>"},{"location":"development/tasks/#stop-all-services","title":"Stop All Services","text":"<pre><code>task teardown\n</code></pre> <p>Stops and removes Docker containers.</p>"},{"location":"development/tasks/#pre-launch-check","title":"Pre-Launch Check","text":"<pre><code>task pre-launch-check\n</code></pre> <p>Validates that all required directories and dependencies exist.</p>"},{"location":"development/tasks/#api-commands","title":"API Commands","text":""},{"location":"development/tasks/#run-django-server","title":"Run Django Server","text":"<pre><code>task api:runserver\n</code></pre> <p>Starts Django development server on <code>http://127.0.0.1:12319</code>.</p>"},{"location":"development/tasks/#django-shell","title":"Django Shell","text":"<pre><code>task api:shell\n</code></pre> <p>Opens Django interactive shell.</p>"},{"location":"development/tasks/#database-migrations","title":"Database Migrations","text":"<p>Create migration files: <pre><code>task api:makemigrations\n</code></pre></p> <p>Apply migrations: <pre><code>task api:migrate\n</code></pre></p>"},{"location":"development/tasks/#client-commands","title":"Client Commands","text":""},{"location":"development/tasks/#start-tauri-dev-mode","title":"Start Tauri Dev Mode","text":"<pre><code>task client:dev\n</code></pre> <p>Launches Tauri window with hot reload.</p>"},{"location":"development/tasks/#build-client","title":"Build Client","text":"<pre><code>task client:build\n</code></pre> <p>Builds production client bundle.</p>"},{"location":"development/tasks/#start-production-client","title":"Start Production Client","text":"<pre><code>task client:start\n</code></pre> <p>Runs production build (requires <code>client:build</code> first).</p>"},{"location":"development/tasks/#database-management","title":"Database Management","text":""},{"location":"development/tasks/#postgresql","title":"PostgreSQL","text":"<p>Open PostgreSQL shell: <pre><code>task db:shell:postgres\n</code></pre></p> <p>Create backup: <pre><code>task db:backup:postgres\n</code></pre></p> <p>Backups saved to <code>./backups/postgres_YYYYMMDD_HHMMSS.sql</code></p> <p>Restore from backup: <pre><code>task db:restore:postgres BACKUP_FILE=backups/postgres_20231127_120000.sql\n</code></pre></p>"},{"location":"development/tasks/#redis","title":"Redis","text":"<p>Open Redis CLI: <pre><code>task db:shell:redis\n</code></pre></p>"},{"location":"development/tasks/#neo4j","title":"Neo4j","text":"<p>Neo4j Browser: http://localhost:7474</p>"},{"location":"development/tasks/#volume-migration","title":"Volume Migration","text":"<p>Migrate all databases from Docker volumes to local bind mounts: <pre><code>task db:migrate-volumes\n</code></pre></p> <p>Migrate individual databases: <pre><code>task db:migrate-volumes:neo4j\ntask db:migrate-volumes:postgres\ntask db:migrate-volumes:redis\n</code></pre></p> <p>These commands copy data from Docker volumes to <code>./data/</code> directories.</p>"},{"location":"development/tasks/#clean-all-data","title":"Clean All Data","text":"<p>Destructive Operation</p> <p>This permanently deletes all database data!</p> <pre><code>task db:clean\n</code></pre> <p>You will be prompted for confirmation.</p>"},{"location":"development/tasks/#testing","title":"Testing","text":""},{"location":"development/tasks/#run-all-tests","title":"Run All Tests","text":"<pre><code>task test\n</code></pre> <p>Runs Django test suite.</p>"},{"location":"development/tasks/#run-specific-test","title":"Run Specific Test","text":"<pre><code>uv run python api/manage.py test agentx_ai.TranslationKitTest\n</code></pre>"},{"location":"development/tasks/#run-single-test-method","title":"Run Single Test Method","text":"<pre><code>uv run python api/manage.py test agentx_ai.TranslationKitTest.test_translate_to_french\n</code></pre>"},{"location":"development/tasks/#documentation","title":"Documentation","text":""},{"location":"development/tasks/#serve-documentation-locally","title":"Serve Documentation Locally","text":"<pre><code>task docs:serve\n</code></pre> <p>Opens documentation at http://127.0.0.1:8000 with live reload.</p>"},{"location":"development/tasks/#build-documentation","title":"Build Documentation","text":"<pre><code>task docs:build\n</code></pre> <p>Builds static documentation site to <code>site/</code> directory.</p>"},{"location":"development/tasks/#deploy-documentation","title":"Deploy Documentation","text":"<pre><code>task docs:deploy\n</code></pre> <p>Deploys documentation to GitHub Pages (requires git repository setup).</p>"},{"location":"development/tasks/#utility-commands","title":"Utility Commands","text":""},{"location":"development/tasks/#default-task","title":"Default Task","text":"<pre><code>task\n</code></pre> <p>Runs sanity check and prompts to start development environment.</p>"},{"location":"development/tasks/#list-all-tasks","title":"List All Tasks","text":"<pre><code>task --list\n</code></pre> <p>Shows all available tasks with descriptions.</p>"},{"location":"development/tasks/#task-help","title":"Task Help","text":"<pre><code>task --help\n</code></pre> <p>Displays Taskfile help information.</p>"},{"location":"development/tasks/#task-dependencies","title":"Task Dependencies","text":"<p>Some tasks automatically run prerequisites:</p> <ul> <li><code>task dev</code> \u2192 runs <code>task runners</code> first</li> <li><code>task client:start</code> \u2192 runs <code>task client:build</code> first</li> <li><code>task runners</code> \u2192 runs <code>task pre-launch-check</code> first</li> </ul>"},{"location":"development/tasks/#environment-specific-tasks","title":"Environment-Specific Tasks","text":""},{"location":"development/tasks/#development_1","title":"Development","text":"<pre><code># Quick iteration cycle\ntask dev              # Start everything\n# Make changes...\ntask test             # Verify changes\ntask teardown         # Stop when done\n</code></pre>"},{"location":"development/tasks/#testing_1","title":"Testing","text":"<pre><code># Run specific tests during development\nuv run python api/manage.py test agentx_ai --keepdb\n</code></pre>"},{"location":"development/tasks/#production-build","title":"Production Build","text":"<pre><code>task client:build     # Build optimized client\ntask api:migrate      # Ensure migrations are applied\n</code></pre>"},{"location":"development/tasks/#custom-task-variables","title":"Custom Task Variables","text":"<p>Some tasks accept variables:</p>"},{"location":"development/tasks/#postgres-restore","title":"Postgres Restore","text":"<pre><code>task db:restore:postgres BACKUP_FILE=path/to/backup.sql\n</code></pre>"},{"location":"development/tasks/#debugging-tasks","title":"Debugging Tasks","text":""},{"location":"development/tasks/#verbose-output","title":"Verbose Output","text":"<pre><code>task --verbose dev\n</code></pre>"},{"location":"development/tasks/#dry-run","title":"Dry Run","text":"<pre><code>task --dry dev\n</code></pre> <p>Shows what would be executed without running commands.</p>"},{"location":"development/tasks/#tips-tricks","title":"Tips &amp; Tricks","text":""},{"location":"development/tasks/#run-multiple-commands","title":"Run Multiple Commands","text":"<pre><code>task install &amp;&amp; task db:init &amp;&amp; task dev\n</code></pre>"},{"location":"development/tasks/#background-execution","title":"Background Execution","text":"<pre><code>task runners &amp;  # Start services in background\n</code></pre>"},{"location":"development/tasks/#watch-mode","title":"Watch Mode","text":"<pre><code># API auto-reloads on file changes\ntask api:runserver\n\n# Client has HMR enabled\ntask client:dev\n</code></pre>"},{"location":"development/tasks/#quick-database-reset","title":"Quick Database Reset","text":"<pre><code>task teardown &amp;&amp; task db:clean &amp;&amp; task db:init &amp;&amp; task runners\n</code></pre> <p>Warning</p> <p>This deletes all data!</p>"},{"location":"development/tasks/#next-steps","title":"Next Steps","text":"<ul> <li>Development Setup - Configure your environment</li> <li>Testing Guide - Write and run tests</li> <li>Contributing - Contribution workflow</li> </ul>"},{"location":"development/testing/","title":"Testing","text":"<p>Guide to writing and running tests for AgentX.</p>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\ntask test\n\n# Run specific test class\nuv run python api/manage.py test agentx_ai.TranslationKitTest\n\n# Run single test method\nuv run python api/manage.py test agentx_ai.TranslationKitTest.test_translate_to_french\n</code></pre>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<p>Tests are located in <code>api/agentx_ai/tests.py</code>.</p>"},{"location":"development/testing/#writing-tests","title":"Writing Tests","text":"<pre><code>from django.test import TestCase\n\nclass MyTestCase(TestCase):\n    def test_example(self):\n        self.assertEqual(1 + 1, 2)\n</code></pre> <p>See Django testing documentation for more information.</p>"},{"location":"features/chat/","title":"Chat Interface","text":"<p>AI conversation interface (planned feature).</p>"},{"location":"features/chat/#status","title":"Status","text":"<p>In development.</p>"},{"location":"features/chat/#planned-features","title":"Planned Features","text":"<ul> <li>Multi-turn conversations</li> <li>Context awareness</li> <li>Memory integration</li> <li>Translation support</li> </ul>"},{"location":"features/memory/","title":"Memory System","text":"<p>AgentX features a sophisticated cognitive memory system inspired by human memory architecture, enabling the AI to remember past conversations, learn from interactions, and build a knowledge graph over time.</p>"},{"location":"features/memory/#overview","title":"Overview","text":"<p>The memory system provides four types of memory:</p> Memory Type Purpose Storage Retrieval Working Current conversation, active goals Redis Direct lookup Episodic Past conversations, events Neo4j + PostgreSQL Vector similarity + temporal Semantic Facts, entities, concepts Neo4j graph Graph traversal + vector Procedural Successful strategies, tool patterns Neo4j graph Task-type matching"},{"location":"features/memory/#key-features","title":"Key Features","text":""},{"location":"features/memory/#episodic-memory","title":"Episodic Memory","text":"<ul> <li>Stores complete conversation history with turns</li> <li>Vector-based semantic search across conversations</li> <li>Temporal filtering and recency boosting</li> <li>Automatic consolidation to semantic memory</li> </ul>"},{"location":"features/memory/#semantic-memory","title":"Semantic Memory","text":"<ul> <li>Entity recognition and tracking (people, organizations, concepts)</li> <li>Fact extraction with confidence scores</li> <li>Knowledge graph with relationships</li> <li>Entity salience scoring and decay</li> </ul>"},{"location":"features/memory/#procedural-memory","title":"Procedural Memory","text":"<ul> <li>Records tool usage patterns</li> <li>Learns successful strategies for tasks</li> <li>Reinforcement learning from outcomes</li> <li>Tool performance analytics</li> </ul>"},{"location":"features/memory/#working-memory","title":"Working Memory","text":"<ul> <li>Redis-based fast access for current session</li> <li>Maintains recent conversation context</li> <li>Active goal tracking</li> <li>Chain-of-thought reasoning steps</li> </ul>"},{"location":"features/memory/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         AGENT RUNTIME                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502  \u2502   LLM API   \u2502  \u2502  Tool Exec  \u2502  \u2502  Planning   \u2502                  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2502         \u2502                \u2502                \u2502                          \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502\n\u2502                          \u25bc                                           \u2502\n\u2502                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502                 \u2502 Memory Interface\u2502                                  \u2502\n\u2502                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc                  \u25bc                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Neo4j      \u2502  \u2502  PostgreSQL   \u2502  \u2502    Redis      \u2502\n\u2502 Graph+Vector  \u2502  \u2502  pgvector     \u2502  \u2502 Working Mem   \u2502\n\u2502               \u2502  \u2502  Time-series  \u2502  \u2502 Cache Layer   \u2502\n\u2502 - Semantic    \u2502  \u2502               \u2502  \u2502               \u2502\n\u2502 - Episodic    \u2502  \u2502 - Raw logs    \u2502  \u2502 - Hot queries \u2502\n\u2502 - Procedural  \u2502  \u2502 - Audit trail \u2502  \u2502 - Session     \u2502\n\u2502 - Entities    \u2502  \u2502 - Timeline    \u2502  \u2502 - Rate limits \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"features/memory/#technology-stack","title":"Technology Stack","text":"Component Technology Purpose Graph Database Neo4j 5.15+ Knowledge graph, vector search, relationships Relational DB PostgreSQL 16+ Logs, audit, time-series, backup vectors Vector Extension pgvector 0.7+ ANN search in PostgreSQL Cache Redis 7+ Working memory, session state Embeddings OpenAI / Local text-embedding-3-small or nomic-embed-text"},{"location":"features/memory/#usage","title":"Usage","text":""},{"location":"features/memory/#basic-usage","title":"Basic Usage","text":"<pre><code>from agentx_ai.kit.agent_memory import AgentMemory, Turn\n\n# Initialize memory for a user\nmemory = AgentMemory(user_id=\"user123\", conversation_id=\"conv456\")\n\n# Store a conversation turn\nturn = Turn(\n    conversation_id=\"conv456\",\n    index=0,\n    role=\"user\",\n    content=\"What's the weather like today?\"\n)\nmemory.store_turn(turn)\n\n# Retrieve relevant memories\ncontext = memory.remember(\"What did we discuss about weather?\")\nprint(context.to_context_string())\n\n# Learn a new fact\nmemory.learn_fact(\n    claim=\"User prefers concise responses\",\n    source=\"inferred\",\n    confidence=0.8\n)\n\n# Track a goal\nfrom agentx_ai.kit.agent_memory import Goal\ngoal = Goal(\n    description=\"Help user plan vacation\",\n    priority=4\n)\nmemory.add_goal(goal)\n\n# Record tool usage for learning\nmemory.record_tool_usage(\n    tool_name=\"web_search\",\n    tool_input={\"query\": \"weather\"},\n    tool_output={\"results\": [...]},\n    success=True,\n    latency_ms=250\n)\n</code></pre>"},{"location":"features/memory/#advanced-retrieval","title":"Advanced Retrieval","text":"<pre><code># Retrieve with filters\ncontext = memory.remember(\n    query=\"Python programming discussion\",\n    top_k=15,\n    include_episodic=True,\n    include_semantic=True,\n    include_procedural=True,\n    time_window_hours=72  # Last 3 days only\n)\n\n# Find what worked for similar tasks\nstrategies = memory.what_worked_for(\"data analysis task\")\nfor strategy in strategies:\n    print(f\"Strategy: {strategy.description}\")\n    print(f\"Tools: {strategy.tool_sequence}\")\n    print(f\"Success rate: {strategy.success_count / max(1, strategy.success_count + strategy.failure_count)}\")\n\n# Get active goals\ngoals = memory.get_active_goals()\nfor goal in goals:\n    print(f\"[P{goal.priority}] {goal.description} - {goal.status}\")\n</code></pre>"},{"location":"features/memory/#background-processing","title":"Background Processing","text":"<p>The system includes a consolidation worker that runs background jobs:</p> <ul> <li>Consolidation (every 15 min): Extracts entities and facts from recent conversations</li> <li>Pattern Detection (hourly): Learns successful strategies from conversation outcomes</li> <li>Memory Decay (daily): Applies time-based decay to salience scores</li> <li>Cleanup (daily): Archives old conversations and removes low-salience entities</li> </ul> <p>To run the worker:</p> <pre><code>python -m agentx_ai.kit.agent_memory.consolidation.worker\n</code></pre>"},{"location":"features/memory/#configuration","title":"Configuration","text":"<p>Configure the memory system via environment variables:</p> <pre><code># Neo4j\nNEO4J_URI=bolt://localhost:7687\nNEO4J_USER=neo4j\nNEO4J_PASSWORD=your_password\n\n# PostgreSQL\nPOSTGRES_URI=postgresql://agent:password@localhost:5432/agent_memory\n\n# Redis\nREDIS_URI=redis://localhost:6379\n\n# Embeddings\nEMBEDDING_PROVIDER=openai  # or \"local\"\nEMBEDDING_MODEL=text-embedding-3-small\nOPENAI_API_KEY=sk-...\n\n# Memory settings\nEPISODIC_RETENTION_DAYS=90\nFACT_CONFIDENCE_THRESHOLD=0.7\nSALIENCE_DECAY_RATE=0.95\nMAX_WORKING_MEMORY_ITEMS=50\n</code></pre>"},{"location":"features/memory/#status","title":"Status","text":"<p>The memory system implementation is complete and syntax-error free. Current status:</p> <ul> <li>\u2705 Core memory interfaces implemented</li> <li>\u2705 Episodic, semantic, procedural, and working memory modules</li> <li>\u2705 Multi-strategy retrieval engine</li> <li>\u2705 Background consolidation worker</li> <li>\u2705 Memory decay and cleanup utilities</li> <li>\u26a0\ufe0f Entity/fact extraction uses placeholder implementations (requires NER/LLM integration)</li> <li>\ud83d\udd32 Database schemas need to be initialized (see Setup Guide)</li> </ul>"},{"location":"features/memory/#next-steps","title":"Next Steps","text":"<ol> <li>Initialize Neo4j with vector indexes and constraints</li> <li>Initialize PostgreSQL with tables and pgvector extension</li> <li>Implement actual entity extraction (spaCy or LLM-based)</li> <li>Implement fact extraction (LLM-based with structured output)</li> <li>Set up Docker Compose for development environment</li> </ol>"},{"location":"features/memory/#related-documentation","title":"Related Documentation","text":"<ul> <li>Memory System Architecture - Detailed technical architecture</li> <li>Memory Setup Guide - Installation and configuration</li> <li>Database Stack - Infrastructure details</li> </ul>"},{"location":"features/translation/","title":"Translation System","text":"<p>Multi-level language detection and translation system.</p>"},{"location":"features/translation/#overview","title":"Overview","text":"<p>Two-level architecture:</p> <ul> <li>Level I: Fast detection (~20 languages)</li> <li>Level II: Comprehensive translation (200+ languages)</li> </ul>"},{"location":"features/translation/#models","title":"Models","text":"<ul> <li>Detection: <code>eleldar/language-detection</code></li> <li>Translation: <code>facebook/m2m100_418M</code> or <code>facebook/nllb-200-distilled-600M</code></li> </ul>"},{"location":"features/translation/#api-usage","title":"API Usage","text":"<pre><code>curl -X POST http://localhost:12319/api/translate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"text\": \"Hello\", \"target_language\": \"fr\"}'\n</code></pre> <p>See API Endpoints for details.</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Configure AgentX for your environment.</p>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>.env</code> file in the project root (optional):</p> <pre><code># Django Settings\nDJANGO_SECRET_KEY=your-secret-key-here\nDJANGO_DEBUG=True\nDJANGO_ALLOWED_HOSTS=localhost,127.0.0.1\n\n# Database Connections\nNEO4J_URI=bolt://localhost:7687\nNEO4J_USER=neo4j\nNEO4J_PASSWORD=your_secure_password\n\nPOSTGRES_URI=postgresql://agent:your_secure_password@localhost:5432/agent_memory\nREDIS_URI=redis://localhost:6379\n\n# API Settings\nAPI_PORT=12319\n</code></pre>"},{"location":"getting-started/configuration/#database-configuration","title":"Database Configuration","text":""},{"location":"getting-started/configuration/#neo4j","title":"Neo4j","text":"<p>Edit <code>docker-compose.yml</code> to customize Neo4j settings:</p> <pre><code>services:\n  neo4j:\n    environment:\n      - NEO4J_AUTH=neo4j/your_secure_password\n      - NEO4J_server_memory_heap_max__size=2G\n      - NEO4J_server_memory_pagecache_size=1G\n</code></pre>"},{"location":"getting-started/configuration/#postgresql","title":"PostgreSQL","text":"<p>Configure PostgreSQL in <code>docker-compose.yml</code>:</p> <pre><code>services:\n  postgres:\n    environment:\n      - POSTGRES_USER=agent\n      - POSTGRES_PASSWORD=your_secure_password\n      - POSTGRES_DB=agent_memory\n</code></pre>"},{"location":"getting-started/configuration/#redis","title":"Redis","text":"<p>Adjust Redis memory limits:</p> <pre><code>services:\n  redis:\n    command: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru\n</code></pre>"},{"location":"getting-started/configuration/#django-settings","title":"Django Settings","text":"<p>Located in <code>api/agentx_api/settings.py</code>:</p>"},{"location":"getting-started/configuration/#database-backend","title":"Database Backend","text":"<p>Currently using SQLite for Django ORM:</p> <pre><code>DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': BASE_DIR / 'db.sqlite3',\n    }\n}\n</code></pre> <p>To switch to PostgreSQL:</p> <pre><code>DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql',\n        'NAME': 'agent_memory',\n        'USER': 'agent',\n        'PASSWORD': 'your_secure_password',\n        'HOST': 'localhost',\n        'PORT': '5432',\n    }\n}\n</code></pre>"},{"location":"getting-started/configuration/#cors-settings","title":"CORS Settings","text":"<p>Configure allowed origins in <code>settings.py</code>:</p> <pre><code>CORS_ALLOWED_ORIGINS = [\n    \"http://localhost:1420\",  # Vite dev server\n    \"tauri://localhost\",       # Tauri window\n]\n</code></pre>"},{"location":"getting-started/configuration/#tauri-configuration","title":"Tauri Configuration","text":"<p>Located in <code>client/src-tauri/tauri.conf.json</code>:</p>"},{"location":"getting-started/configuration/#window-settings","title":"Window Settings","text":"<pre><code>{\n  \"windows\": [\n    {\n      \"title\": \"AgentX\",\n      \"width\": 800,\n      \"height\": 600,\n      \"resizable\": true,\n      \"fullscreen\": false\n    }\n  ]\n}\n</code></pre>"},{"location":"getting-started/configuration/#development-url","title":"Development URL","text":"<pre><code>{\n  \"build\": {\n    \"devUrl\": \"http://localhost:1420\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#translation-models","title":"Translation Models","text":"<p>Configure models in <code>api/agentx_ai/kit/translation.py</code>:</p>"},{"location":"getting-started/configuration/#language-detection-model","title":"Language Detection Model","text":"<pre><code>DETECTION_MODEL = \"eleldar/language-detection\"\n</code></pre>"},{"location":"getting-started/configuration/#translation-model","title":"Translation Model","text":"<p>Currently using M2M100:</p> <pre><code>TRANSLATION_MODEL = \"facebook/m2m100_418M\"\n</code></pre> <p>To switch to NLLB-200 (larger, more accurate):</p> <pre><code>TRANSLATION_MODEL = \"facebook/nllb-200-distilled-600M\"\n</code></pre> <p>Note</p> <p>Larger models provide better quality but require more memory and slower inference.</p>"},{"location":"getting-started/configuration/#development-tools","title":"Development Tools","text":""},{"location":"getting-started/configuration/#task-configuration","title":"Task Configuration","text":"<p>Edit <code>Taskfile.yaml</code> to customize commands:</p> <pre><code>tasks:\n  api:runserver:\n    dir: api/\n    cmds:\n      - uv run python manage.py runserver 127.0.0.1:12319\n</code></pre>"},{"location":"getting-started/configuration/#vite-configuration","title":"Vite Configuration","text":"<p>Located in <code>client/vite.config.ts</code>:</p> <pre><code>export default defineConfig({\n  server: {\n    port: 1420,\n    strictPort: true,\n  },\n  // ... other settings\n})\n</code></pre>"},{"location":"getting-started/configuration/#security-considerations","title":"Security Considerations","text":""},{"location":"getting-started/configuration/#production-checklist","title":"Production Checklist","text":"<ul> <li> Change default database passwords</li> <li> Set <code>DJANGO_DEBUG=False</code></li> <li> Configure <code>DJANGO_ALLOWED_HOSTS</code></li> <li> Use environment variables for secrets</li> <li> Enable HTTPS for API</li> <li> Configure firewall rules</li> <li> Set up database backups</li> <li> Review CORS settings</li> </ul>"},{"location":"getting-started/configuration/#password-management","title":"Password Management","text":"<p>Never commit passwords to version control. Use:</p> <ul> <li>Environment variables</li> <li>Secret management tools (HashiCorp Vault, AWS Secrets Manager)</li> <li><code>.env</code> files (gitignored)</li> </ul>"},{"location":"getting-started/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"getting-started/configuration/#model-loading","title":"Model Loading","text":"<p>Translation models are loaded at startup. To reduce memory:</p> <pre><code># Use smaller models\nTRANSLATION_MODEL = \"facebook/m2m100_418M\"  # ~500MB\n# vs\nTRANSLATION_MODEL = \"facebook/nllb-200-3.3B\"  # ~13GB\n</code></pre>"},{"location":"getting-started/configuration/#database-connections","title":"Database Connections","text":"<p>Adjust connection pools in production:</p> <pre><code>DATABASES = {\n    'default': {\n        # ...\n        'OPTIONS': {\n            'MAX_CONNS': 20,\n            'MIN_CONNS': 5,\n        }\n    }\n}\n</code></pre>"},{"location":"getting-started/configuration/#redis-caching","title":"Redis Caching","text":"<p>Configure Redis for optimal performance:</p> <pre><code># In docker-compose.yml\ncommand: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru\n</code></pre>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Development Setup - Advanced configuration</li> <li>Database Migration - Data management</li> <li>Task Commands - Available automation</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Get AgentX up and running on your local machine.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing AgentX, ensure you have:</p> <ul> <li>Python 3.10+ - For the Django API</li> <li>Node.js 18+ - For the Tauri client</li> <li>Docker &amp; Docker Compose - For database services</li> <li>uv - Python package manager (installation guide)</li> <li>bun - Fast JavaScript runtime (installation guide)</li> <li>Task - Task runner (installation guide)</li> </ul>"},{"location":"getting-started/installation/#quick-install","title":"Quick Install","text":""},{"location":"getting-started/installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/yourusername/agentx-source.git\ncd agentx-source\n</code></pre>"},{"location":"getting-started/installation/#2-install-dependencies","title":"2. Install Dependencies","text":"<pre><code>task install\n</code></pre> <p>This command will:</p> <ul> <li>Install Python dependencies via <code>uv sync</code></li> <li>Install client dependencies via <code>bun install</code></li> <li>Install concurrently for running multiple services</li> </ul>"},{"location":"getting-started/installation/#3-initialize-databases","title":"3. Initialize Databases","text":"<pre><code>task db:init\n</code></pre> <p>This creates the required data directories for:</p> <ul> <li>Neo4j graph database</li> <li>PostgreSQL with pgvector</li> <li>Redis cache</li> </ul>"},{"location":"getting-started/installation/#4-start-development-environment","title":"4. Start Development Environment","text":"<pre><code>task dev\n</code></pre> <p>This will:</p> <ol> <li>Start Docker containers (Neo4j, Postgres, Redis)</li> <li>Launch Django API on <code>http://localhost:12319</code></li> <li>Launch Tauri development window</li> </ol>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":""},{"location":"getting-started/installation/#check-api","title":"Check API","text":"<pre><code>curl http://localhost:12319/api/index\n</code></pre> <p>Expected response: <pre><code>{\n  \"status\": \"ok\",\n  \"message\": \"AgentX API is running\"\n}\n</code></pre></p>"},{"location":"getting-started/installation/#check-databases","title":"Check Databases","text":"<pre><code># Neo4j Browser\nopen http://localhost:7474\n\n# Redis Commander (optional GUI)\nopen http://localhost:8081\n</code></pre> <p>Default credentials:</p> <ul> <li>Neo4j: <code>neo4j</code> / <code>your_secure_password</code></li> <li>PostgreSQL: <code>agent</code> / <code>your_secure_password</code></li> </ul>"},{"location":"getting-started/installation/#manual-installation","title":"Manual Installation","text":"<p>If you prefer to install components individually:</p>"},{"location":"getting-started/installation/#python-api","title":"Python API","text":"<pre><code># Install dependencies\nuv sync\n\n# Run migrations\ntask api:migrate\n\n# Start API server\ntask api:runserver\n</code></pre>"},{"location":"getting-started/installation/#tauri-client","title":"Tauri Client","text":"<pre><code>cd client\n\n# Install dependencies\nbun install\n\n# Start development server\nbunx tauri dev\n</code></pre>"},{"location":"getting-started/installation/#database-services","title":"Database Services","text":"<pre><code># Start all databases\ntask runners\n\n# Or start individually\ndocker-compose up -d neo4j\ndocker-compose up -d postgres\ndocker-compose up -d redis\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#port-conflicts","title":"Port Conflicts","text":"<p>If ports are already in use, modify <code>docker-compose.yml</code>:</p> <ul> <li>Neo4j: 7474 (browser), 7687 (bolt)</li> <li>PostgreSQL: 5432</li> <li>Redis: 6379</li> <li>Django API: 12319</li> <li>Vite dev server: 1420</li> </ul>"},{"location":"getting-started/installation/#missing-data-directories","title":"Missing Data Directories","text":"<p>If you see errors about missing data directories:</p> <pre><code>task pre-launch-check\n</code></pre> <p>This will show which directories are missing and how to fix them.</p>"},{"location":"getting-started/installation/#docker-volume-migration","title":"Docker Volume Migration","text":"<p>If you have existing data in Docker volumes:</p> <pre><code>task db:migrate-volumes\n</code></pre> <p>This migrates data from Docker volumes to local bind mounts in <code>./data/</code>.</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Learn basic usage</li> <li>Configuration - Customize your setup</li> <li>Development Setup - Set up for development</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get started with AgentX in 5 minutes.</p>"},{"location":"getting-started/quickstart/#starting-agentx","title":"Starting AgentX","text":""},{"location":"getting-started/quickstart/#development-mode","title":"Development Mode","text":"<pre><code>task dev\n</code></pre> <p>This starts:</p> <ul> <li>All database services (Neo4j, Postgres, Redis)</li> <li>Django API on port 12319</li> <li>Tauri desktop application</li> </ul>"},{"location":"getting-started/quickstart/#api-only","title":"API Only","text":"<pre><code>task api:runserver\n</code></pre>"},{"location":"getting-started/quickstart/#client-only","title":"Client Only","text":"<pre><code>cd client\nbunx tauri dev\n</code></pre>"},{"location":"getting-started/quickstart/#using-the-translation-api","title":"Using the Translation API","text":""},{"location":"getting-started/quickstart/#detect-language","title":"Detect Language","text":"<pre><code>curl http://localhost:12319/api/language-detect\n</code></pre>"},{"location":"getting-started/quickstart/#translate-text","title":"Translate Text","text":"<pre><code>curl -X POST http://localhost:12319/api/translate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"text\": \"Hello, world!\",\n    \"target_language\": \"fr\"\n  }'\n</code></pre> <p>Response: <pre><code>{\n  \"original\": \"Hello, world!\",\n  \"translated\": \"Bonjour le monde!\",\n  \"source_language\": \"en\",\n  \"target_language\": \"fr\",\n  \"confidence\": 0.98\n}\n</code></pre></p>"},{"location":"getting-started/quickstart/#supported-language-codes","title":"Supported Language Codes","text":"<p>Use ISO 639-1 codes for target languages:</p> <ul> <li><code>en</code> - English</li> <li><code>fr</code> - French</li> <li><code>es</code> - Spanish</li> <li><code>de</code> - German</li> <li><code>zh</code> - Chinese</li> <li><code>ja</code> - Japanese</li> <li><code>ar</code> - Arabic</li> <li>And 193+ more...</li> </ul>"},{"location":"getting-started/quickstart/#using-the-desktop-application","title":"Using the Desktop Application","text":""},{"location":"getting-started/quickstart/#tab-navigation","title":"Tab Navigation","text":"<p>The application has four main tabs:</p> <ol> <li>Dashboard - Overview and stats</li> <li>Translation - Interactive translation interface</li> <li>Chat - AI conversation interface</li> <li>Tools - Utilities and settings</li> </ol>"},{"location":"getting-started/quickstart/#translation-tab","title":"Translation Tab","text":"<ol> <li>Enter text in the source field</li> <li>Select target language</li> <li>Click \"Translate\"</li> <li>View results with confidence scores</li> </ol>"},{"location":"getting-started/quickstart/#database-access","title":"Database Access","text":""},{"location":"getting-started/quickstart/#postgresql-shell","title":"PostgreSQL Shell","text":"<pre><code>task db:shell:postgres\n</code></pre>"},{"location":"getting-started/quickstart/#redis-cli","title":"Redis CLI","text":"<pre><code>task db:shell:redis\n</code></pre>"},{"location":"getting-started/quickstart/#neo4j-browser","title":"Neo4j Browser","text":"<p>Open http://localhost:7474</p> <p>Credentials: <code>neo4j</code> / <code>your_secure_password</code></p>"},{"location":"getting-started/quickstart/#common-tasks","title":"Common Tasks","text":""},{"location":"getting-started/quickstart/#run-tests","title":"Run Tests","text":"<pre><code>task test\n</code></pre>"},{"location":"getting-started/quickstart/#database-backup","title":"Database Backup","text":"<pre><code>task db:backup:postgres\n</code></pre> <p>Backups are saved in <code>./backups/</code></p>"},{"location":"getting-started/quickstart/#clean-database","title":"Clean Database","text":"<pre><code>task db:clean\n</code></pre> <p>Warning</p> <p>This removes all database data. Use with caution!</p>"},{"location":"getting-started/quickstart/#stop-services","title":"Stop Services","text":"<pre><code>task teardown\n</code></pre> <p>Or press <code>Ctrl+C</code> to stop the dev environment.</p>"},{"location":"getting-started/quickstart/#development-workflow","title":"Development Workflow","text":"<ol> <li>Start dev environment: <code>task dev</code></li> <li>Make changes to API or client code</li> <li>Hot reload happens automatically</li> <li>Vite for frontend changes</li> <li>Django autoreload for API changes</li> <li>Run tests: <code>task test</code></li> <li>Commit changes: <code>git commit</code></li> <li>Stop services: <code>Ctrl+C</code> or <code>task teardown</code></li> </ol>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Guide - Customize settings</li> <li>Architecture Overview - Understand the system</li> <li>Development Setup - Advanced development</li> </ul>"}]}